<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-12-29T20:50:41+01:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Andreas Bloch</title><entry><title type="html">An Overview of Collaborative Filtering Algorithms for Implicit Feedback Data</title><link href="http://localhost:4000/An-Overview-of-Collaborative-Filtering-Algorithms/" rel="alternate" type="text/html" title="An Overview of Collaborative Filtering Algorithms for Implicit Feedback Data" /><published>2019-12-16T08:00:00+01:00</published><updated>2019-12-16T08:00:00+01:00</updated><id>http://localhost:4000/An-Overview-of-Collaborative-Filtering-Algorithms</id><content type="html" xml:base="http://localhost:4000/An-Overview-of-Collaborative-Filtering-Algorithms/">&lt;p&gt;This blogpost gives an overview of today’s most predominant types of 
recommender systems for collaborative filtering from implicit feedback data. 
The overview is by no means exhaustive, but it should provide the reader with 
a good overview about the topic.&lt;/p&gt;

&lt;p&gt;First, some background about recommender systems is given. Also, the setting
of &lt;em&gt;collaborative filtering from implicit feedback data&lt;/em&gt; is defined and 
the typical application structure of a recommender service is explained. 
Then, several collaborative filtering models are described in more detail
together with a discussion on their advantages and disadvantages. Finally, a summary
of the different approaches is given. A slide deck accompanying the article 
can be found here:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/files/collaborative-filtering-algorithms-for-implicit-feedback-data.pdf&quot; target=&quot;_blank&quot;&gt;
&lt;img src=&quot;/img/2019-12-16-An-Overview-of-Collaborative-Filtering-Algorithms/slide-deck.png?v=1&quot; alt=&quot;Slide Deck&quot; width=&quot;60%&quot; /&gt;
&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;background-on-recommender-systems&quot;&gt;Background on Recommender Systems&lt;/h2&gt;

&lt;p&gt;Recommender systems are at the heart of any of today’s large-scale e-commerce,
news, content-streaming, dating or search platforms.  A critical success factor
of such platforms is the ability to reduce the overwhelming amount of options to
a few relevant recommendations matching the users’ individual and trending
interests.&lt;/p&gt;

&lt;p&gt;According to McKinsey &amp;amp; Company, 35% of the consumer purchases on Amazon and
75% of the views on Netflix in 2012 came from product recommendations based on
recommendation engines &lt;a class=&quot;citation&quot; href=&quot;#mckinsey&quot;&gt;[1]&lt;/a&gt;. 
Goodwater Capital &lt;a class=&quot;citation&quot; href=&quot;#goodwatercap&quot;&gt;[2]&lt;/a&gt;
also reports that in 2017, 31% of the tracks listened on Spotify stemmed from
personalized playlists generated by Spotify’s recommender system. These numbers
clearly demonstrate the significance of algorithmic recommendations in online
services.&lt;/p&gt;

&lt;p&gt;Connecting customers to products that they love is critical to both, the
customers and the companies. Because if users fail to find the products that
interest and engage them, they tend to abandon the platforms
&lt;a class=&quot;citation&quot; href=&quot;#bennett2007netflix&quot;&gt;[3]&lt;/a&gt;. In a report about the 
business-value of their recommender algorithms Netflix describes how the reduction 
of the monthly churn both increases the lifetime value of existing subscribers, 
and reduces the number of new subscribers that they need to acquire to replace 
cancelled members. They estimate the combined effect of personalization and
recommendations to save them more than the exorbitant amount of $1B per year
&lt;a class=&quot;citation&quot; href=&quot;#gomez2016netflix&quot;&gt;[4]&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The urgency of the capability to provide relevant and personalized
recommendations can also be seen in the prize money of $1M that Netflix
advertised in its famous “Netflix Prize” competition of 2006 for the first
team that could improve the Netflix algorithm’s RMSE by 10%
&lt;a class=&quot;citation&quot; href=&quot;#koren2009matrix&quot;&gt;[5]&lt;/a&gt;. The competition inspired a multitude of researchers to
participate and to contribute to the development of next-generation recommender
systems. In the end, the grand prize was won by Yehuda Koren, Robert Bell and
Chris Volinsky in 2009 who had developed a model that blended the predictions of
hundreds of predictors, including a plethora of matrix factorization models,
neighbourhood models and restricted Boltzmann machines &lt;a class=&quot;citation&quot; href=&quot;#koren2009bellkor&quot;&gt;[6]&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Ironically, in 2012 Netflix published in a blogpost of theirs &lt;a class=&quot;citation&quot; href=&quot;#netflixblog&quot;&gt;[7]&lt;/a&gt;
that they never happened to use Koren et al.’s algorithm in production due to its
engineering costs: “the additional accuracy gains that we measured did not seem
to justify the engineering effort needed to bring them into a production
environment.” Anyways, the field of recommender systems has certainly
profited from the inventions that were sparked by virtue of the competition.&lt;/p&gt;

&lt;h2 id=&quot;the-collaborative-filtering-setting&quot;&gt;The Collaborative Filtering Setting&lt;/h2&gt;

&lt;p&gt;Many different types of recommender systems have evolved over the years.
One way to characterize recommender systems is through the information that 
they consider to produce their rankings:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Collaborative Filtering:&lt;/strong&gt; In collaborative filtering the
recommender system purely learns form the interaction patterns between users
and items &lt;a class=&quot;citation&quot; href=&quot;#hu2008collaborative&quot;&gt;[8]&lt;/a&gt;. 
The contents and features of the items and users are completely ignored. 
Users and items are just treated as enumerated nodes of an undirected 
(weighted or unweighted) bipartite graph $G=(U\cup I, E)$ where the 
items $I$ are indexed as $i_1,…,i_{\card{I}}$ and the users $U$ are indexed as
$u_1,…,u_{\card{U}}$. Nothing more than the vertices, edges $\set{u_j,i_k}$ and
maybe a some edge weights $w_{u_j,i_k}$ are known. Hence collaborative filtering 
corresponds to predicting promising links from user nodes to item nodes based 
on the observed common connection patterns. It is called &lt;em&gt;collaborative&lt;/em&gt; filtering,
because in the collaborative filtering approaches it is commonly assumed that learning the
interaction patterns of one user (e.g., the items he has interacted) will
help to predict relevant items for another user that has a similar
interaction pattern (in terms of interacted items) as the latter user.
Hence it is as if users were &lt;em&gt;collaborating&lt;/em&gt; to produce the rankings of items
for each other.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Content-Based:&lt;/strong&gt; In content-based recommender systems, the
recommender system additionally learns from the content and features of the items 
(e.g., image location and data or text data) and sometimes also from the features 
of the users, to produce a list of rankings as done for example in 
&lt;a class=&quot;citation&quot; href=&quot;#cml&quot;&gt;[9]&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Context-Aware:&lt;/strong&gt; These recommender systems include additional information 
about a user’s context &lt;a class=&quot;citation&quot; href=&quot;#adomavicius2011context&quot;&gt;[10]&lt;/a&gt;,
e.g., whether he is accessing the service from a mobile or desktop client, 
his current geolocation, his current time of day, whether he is stationary or 
travelling, or whether he is in a quiet or noisy place.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This blogpost is purely concerned with the &lt;em&gt;collaborative filtering&lt;/em&gt; setting. 
However, most of the collaborative filtering approaches can usually be extended 
to include the other aforementioned information sources, as for example done in the
approach of &lt;a class=&quot;citation&quot; href=&quot;#cml&quot;&gt;[9]&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;explicit-vs-implicit-feedback-data&quot;&gt;Explicit VS Implicit Feedback Data&lt;/h2&gt;

&lt;p&gt;The training of recommender systems relies on data that is gathered from the
feedback that users gave to items. This feedback can be divided into two
categories as defined in &lt;a class=&quot;citation&quot; href=&quot;#oard1998implicit&quot;&gt;[11]&lt;/a&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Explicit Feedback:&lt;/strong&gt; Here a user explicitly gives a rating to an
item on a certain scale.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Implicit Feedback:&lt;/strong&gt; Here a user implicitly provides the
information about the relevance of an item by interacting with it according
to a certain notion of time, e.g., a certain amount of times, 
or a total amount of time, or the percentage watched of a movie.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The relevance of algorithms capable of dealing with implicit feedback data can
be motivated by the natural abundance of implicit feedback data versus the
usual scarcity of explicit feedback data &lt;a class=&quot;citation&quot; href=&quot;#davidson2010youtube&quot;&gt;[12]&lt;/a&gt;. 
This blogpost is purely concerned with &lt;em&gt;binary implicit feedback&lt;/em&gt; data,
as done in most of the academic literature.&lt;/p&gt;

&lt;h2 id=&quot;recommender-service-an-interplay-of-a-retrieval-and-a-ranking-system&quot;&gt;Recommender Service: An Interplay of a Retrieval and a Ranking System&lt;/h2&gt;

&lt;p&gt;Before looking at our first concrete collaborative filtering model, let’s
first have a look at how a recommender service is usually structured.
A common practice &lt;a class=&quot;citation&quot; href=&quot;#cheng2016wide&quot;&gt;[13]&lt;/a&gt; is to 
structure a &lt;em&gt;recommendation service&lt;/em&gt; into two components as follows :&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;A &lt;strong&gt;retrieval system&lt;/strong&gt; that retrieves potential relevant items in
a very efficient manner (e.g., KD-trees &lt;a class=&quot;citation&quot; href=&quot;#kdtrees&quot;&gt;[14]&lt;/a&gt;), 
maximum inner product search (MIPS) &lt;a class=&quot;citation&quot; href=&quot;#mips&quot;&gt;[15]&lt;/a&gt;, 
locality-sensitive hashing (LSH) &lt;a class=&quot;citation&quot; href=&quot;#lsh1&quot;&gt;[16, 17, 18]&lt;/a&gt;,
or also neural-network based methods &lt;a class=&quot;citation&quot; href=&quot;#davidson2010youtube&quot;&gt;[12]&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A &lt;strong&gt;ranking system&lt;/strong&gt;, which we also refer to as &lt;em&gt;recommender
system&lt;/em&gt;, which usually runs a more expensive and sophisticated algorithm
to precisely rank the retrieved potential positive candidates such that 
they can be presented in their final estimated relevance order to a user
&lt;a class=&quot;citation&quot; href=&quot;#davidson2010youtube&quot;&gt;[12]&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The figure below illustrates the interplay of a retrieval and a ranking system. 
Whether to use just a recommender system, or a combination of a retrieval and 
recommender system depends on the size of the data (in terms of number of users 
and items) and the computational cost of the recommender system. If the ranking 
has a high computational cost, and there are lots of items, then it makes sense 
to have a retrieval system that retrieves a subset of potential candidates in a 
cheap way. An important thing to note here is that, besides the ranking accuracy
of the ranking system, also the quality of the subsample retrieved by 
the retrieval system strongly affects the performance metrics of the entire 
recommender service.&lt;/p&gt;

&lt;div class=&quot;figure-with-caption&quot;&gt;
&lt;img src=&quot;/img/2019-12-16-An-Overview-of-Collaborative-Filtering-Algorithms/retrieval-and-ranking-system.png?v=1&quot; alt=&quot;Interplay of Retrieval and Ranking System&quot; width=&quot;100%&quot; /&gt;
&lt;div class=&quot;figure-caption&quot;&gt;
The illustration by &lt;a class=&quot;citation&quot; href=&quot;#cheng2016wide&quot;&gt;[13]&lt;/a&gt; shows the 
typical structuring of a recommender service into a retrieval system and a 
ranking system.
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;In the collaborative filtering setting, the query is just a user index and the 
result is a ranked list of indices of recommended items. As depicted, the 
retrieval system usually returns a subset in the order of $N=100$ items to 
the ranking system.&lt;/p&gt;

&lt;p&gt;Now that we have enough background on recommender systems we can have a look at
the first collaborative filtering model.&lt;/p&gt;

&lt;h2 id=&quot;item-popularity&quot;&gt;Item Popularity&lt;/h2&gt;

&lt;p&gt;The Item Popularity model is a very simple and efficient ranking model that
simply recommends items based on their popularities. The more popular an item
is, the higher up it is on its recommendation list. Thus, the ranking of an item
$i$ for user $u$ is simply computed through&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{x}_{ui}=\frac{\#\text{interactions with item }i}{\# \text{interactions in total}}.&lt;/script&gt;

&lt;p&gt;Hence, it completely ignores the user’s features, which can be
disadvantageous if one wants to create recommendations tailored to a user’s
preferences.&lt;/p&gt;

&lt;p&gt;Nevertheless, it can be a very powerful prediction model.
Its strengths lie in its simplicity and its efficiency. The Item Popularity
model can be particularly useful in situations where there is little information
known about a user’s preferences. Therefore, it is often used to overcome
the cold-start problem.&lt;/p&gt;

&lt;p&gt;A reason why the Item Popularity model works quite well in practice is
because, usually, the popularity of items is distributed according to a
power-law: most of the interactions happen with a few popular items, and the
rest of the items only have a few interactions. The following plot
illustrates how the number of interactions per item is distributed according to a
power-law for the &lt;a href=&quot;https://grouplens.org/datasets/movielens/20m/&quot;&gt;Movielens-20M&lt;/a&gt;
dataset.&lt;/p&gt;

&lt;div class=&quot;figure-with-caption&quot;&gt;
&lt;img src=&quot;/img/2019-12-16-An-Overview-of-Collaborative-Filtering-Algorithms/movielens-20M-item-popularity.png?v=1&quot; alt=&quot;MovieLens-20M Item Popularity&quot; width=&quot;100%&quot; /&gt;
&lt;div class=&quot;figure-caption&quot;&gt;
The plot shows the number of ratings per movie in descending order for
the MovieLens-20M dataset. One can clearly observe the power-law nature of the
popularities of the movies in terms of their number of ratings.
&lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;matrix-factorization-mf&quot;&gt;Matrix Factorization (MF)&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Matrix factorization (MF)&lt;/em&gt; predicts the relevance $\hat{x}_{ui}$ of an
item $i\in I$ for a user $u\in U$ through the dot product&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{x}_{ui}=\scprod{\vx_u,\vx_i},&lt;/script&gt;

&lt;p&gt;where $\vx_u$ and $\vx_i$ are $d$-dimensional representations of the user $u$
and item $i$ in a &lt;em&gt;latent factor space&lt;/em&gt;. These latent factor representations
of users and items are the parameters $\vtheta$ that are aimed to be learned:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\vtheta=\set{\MX_U,\MX_I},
\qquad
\MX_U\in\R^{\card{U}\times d},\quad
\MX_I\in\R^{\card{I}\times d}.&lt;/script&gt;

&lt;p&gt;Several works showed how these latent factor space dimensions tend to capture
concepts of users and items, e.g., “male” or “female” for users, or “serious” vs
“escapist” for movies as illustrated below from the work of &lt;a class=&quot;citation&quot; href=&quot;#koren2009matrix&quot;&gt;[5]&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;figure-with-caption&quot;&gt;
&lt;img src=&quot;/img/2019-12-16-An-Overview-of-Collaborative-Filtering-Algorithms/mf-latent-factors-interpretation.png?v=1&quot; alt=&quot;Concepts captured in latent factor space&quot; width=&quot;100%&quot; /&gt;
&lt;div class=&quot;figure-caption&quot;&gt;
The illustration by &lt;a class=&quot;citation&quot; href=&quot;#koren2009matrix&quot;&gt;[5]&lt;/a&gt; shows
how the latent factor dimensions tend to capture concepts about users or items.
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;For &lt;em&gt;explicit&lt;/em&gt; feedback data the parameters are trained by minimizing the
squared loss over the observed rankings $x_{ui}$ of the interaction matrix 
$\MX\in\R^{\card{U}\times\card{I}}$, collected as training instances $(u,i)\in\cD$:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\cL(\vtheta)
=
\sum_{(u,i)\in\cD}\left(x_{ui}-\hat{x}_{ui}\right)^2
=
\sum_{(u,i)\in\cD}\left(x_{ui}-\scprod{\vx_u,\vx_i}\right)^2.&lt;/script&gt;

&lt;p&gt;Some approaches for &lt;em&gt;implicit&lt;/em&gt; feedback data, such as
&lt;a class=&quot;citation&quot; href=&quot;#sarwar2000application&quot;&gt;[19, 20]&lt;/a&gt;, rely on
binarization and imputation of the unobserved entries of $\MX$ as 0, turning the
optimization problem into&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\cL(\vtheta)=\norm{\MX - \MX_U\MX_I^T}_2^2.&lt;/script&gt;

&lt;p&gt;The latter loss clearly shows why the recommender system approach has its name
&lt;em&gt;matrix factorization&lt;/em&gt;. Under some conditions, one can assume that
$\rank(\MX_U\MX_I^\T)\leq d$, making the problem tightly
related to Singular Value Decomposition (SVD) and Principal Component Analysis (PCA).&lt;/p&gt;

&lt;p&gt;Other approaches for &lt;em&gt;implicit&lt;/em&gt; feedback data argue that one should still
impute the non-observed interactions as $0$, but weigh the
prediction errors for observed and unobserved interactions differently. Such
approaches fall under the category of &lt;em&gt;weighted regularized matrix
factorization (WMRF)&lt;/em&gt;, having a training loss of the form&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\cL(\vtheta)
=
\sum_{(u,i)\in\cD} c_{ui}(x_{ui}-\hat{x}_{ui})^2.&lt;/script&gt;

&lt;p&gt;where the weights $c_{ui}$ are chosen according to a &lt;em&gt;weighting-strategy&lt;/em&gt;.
Hu et al. &lt;a class=&quot;citation&quot; href=&quot;#hu2008collaborative&quot;&gt;[8]&lt;/a&gt;, Pan et al. &lt;a class=&quot;citation&quot; href=&quot;#pan2008one&quot;&gt;[21]&lt;/a&gt; and He et al.
&lt;a class=&quot;citation&quot; href=&quot;#eals&quot;&gt;[22]&lt;/a&gt;, proposed various weighting-schemes that all assign a fixed weight
$c_{ui}=1$ to the observed interactions, and the weights $c_{ui}$ for the
unobserved interactions are chosen according to one of the following strategies:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Uniform-Weighting:&lt;/strong&gt; Chooses some fixed weight $c_{ui}\in[0,1)$,
meaning that all unobserved interactions share the same probability of 
being negative examples.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;User-Activity Based:&lt;/strong&gt; Chooses the weight based on the number of
ratings that a user $u$ gave: $c_{ui}\propto\norm{\vx_u}_1$. With the argument
that, the more a user has interacted with the system, the more confident one can
be about the inferred irrelevance of the user’s left-out items.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Item-Popularity Based:&lt;/strong&gt; Assigns lower weights to popular items.
The rationale behind this is: the more popular an item is, the more likely it
is to be known. Hence, a non-interaction on a popular item is more likely to
be due to its true irrelevance to a user.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Other more advanced models also train a global bias $\mu$, and user- and
item-specific biases $\mu_u$ and $\mu_i$ to predict the rankings as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{x}_{ui}=\scprod{\vx_u,\vx_i}+\mu_u+\mu_i+\mu.&lt;/script&gt;

&lt;p&gt;This aims to compensate for the systematic tendencies that some users tend to
give higher ratings than others, and some items tend to receive higher ratings
than others. The rationale behind this is that the latent concepts (the
$d$-dimensions of the latent factor space) should not be used to explain these
systematic tendencies &lt;a class=&quot;citation&quot; href=&quot;#koren2009matrix&quot;&gt;[5]&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It is also a common practice to regularize the user- and item-embeddings and the
means with L2-regularization&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Omega(\theta)
=
\norm{\MX_U}_2^2
+\norm{\MX_I}_2^2
+\norm{\vmu_U}_2^2
+\norm{\vmu_I}_2^2
+\mu^2.&lt;/script&gt;

&lt;p&gt;This form of regularization can also be motivated from a probabilistic
perspective where the user- and item-embeddings and the means are assumed to be
distributed according to multivariate Gaussian distributions in the latent factor
space. For a derivation see &lt;a class=&quot;citation&quot; href=&quot;#mnih2008probabilistic&quot;&gt;[23]&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In the famous Netflix Prize, launched in 2006, the majority of the successful
recommender systems were using matrix-factorization approaches
&lt;a class=&quot;citation&quot; href=&quot;#bennett2007netflix&quot;&gt;[3]&lt;/a&gt;.  For many years, matrix factorization 
has been the ranking model of 
first-choice and a lot of improvements and extensions have been proposed, including:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Alternating Least-Squares (ALS):&lt;/strong&gt; Various &lt;em&gt;alternating
least-squares (ALS)&lt;/em&gt; optimization approaches, such as eALS &lt;a class=&quot;citation&quot; href=&quot;#eals&quot;&gt;[22]&lt;/a&gt;
and ALS-WR &lt;a class=&quot;citation&quot; href=&quot;#alswr&quot;&gt;[24]&lt;/a&gt;, have been developed. These approaches aim to
speed-up the convergence of the non-convex optimization problem through
the surrogate of two convex optimization problems. ALS works through the following 
alternation: at each iteration, once the user embeddings are fixed and the solutions for the
items are obtained in a closed-form, and vice-versa.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Including Temporal Dimensions:&lt;/strong&gt; Another direction of work, e.g.
&lt;a class=&quot;citation&quot; href=&quot;#koren2009collaborative&quot;&gt;[25, 26]&lt;/a&gt;, has been 
concerned with incorporating temporal dimensions into matrix factorization. These
approaches model the trends of items and the changes of users’ tastes by expressing 
the user and item embeddings, and also the biases, as functions of time.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Non-Negative Matrix Factorization:&lt;/strong&gt; For some ranking applications it might
be desirable to only have predictions that are positive.
To this end, several works have been concerned with applying non-negative matrix
factorization to collaborative filtering, including
&lt;a class=&quot;citation&quot; href=&quot;#luo2014efficient&quot;&gt;[27, 28]&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;On-line Learning and Regret Bounds:&lt;/strong&gt; A lot of effort has
also been invested in the development of on-line learning algorithms (e.g.
&lt;a class=&quot;citation&quot; href=&quot;#eals&quot;&gt;[22, 29]&lt;/a&gt;) and the derivation of regret bounds (e.g.
&lt;a class=&quot;citation&quot; href=&quot;#dadkhahi2018alternating&quot;&gt;[30, 31]&lt;/a&gt;), making it 
possible to scale matrix factorization to big-data settings with on-line learning
and convenient regret bounds.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note that while all examples here have been using the squared loss,
&lt;em&gt;matrix factorization&lt;/em&gt; can also be trained using the pair-wise BPR loss as done in
&lt;a class=&quot;citation&quot; href=&quot;#rendle2009bpr&quot;&gt;[32]&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;All-in-all, matrix factorization has demonstrated to be a powerful and
successful recommender model. Indeed, it had been successfully used to do
YouTube video recommendations, until it got replaced by neural network
approaches recently &lt;a class=&quot;citation&quot; href=&quot;#davidson2010youtube&quot;&gt;[12]&lt;/a&gt;. The fact that, at its heart,
matrix factorization only uses a bi-linear form to predict the rankings, makes
it computationally very attractive. However, as we will see in what follows,
recent state-of-the-art approaches critique the inner product for failing at
propagating similarities &lt;a class=&quot;citation&quot; href=&quot;#cml&quot;&gt;[9]&lt;/a&gt; and for being too rigid, in the sense that
it is only a bi-linear form as opposed to a more powerfulnon-linear prediction function
&lt;a class=&quot;citation&quot; href=&quot;#ncf&quot;&gt;[33]&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;collaborative-metric-learning-cml&quot;&gt;Collaborative Metric Learning (CML)&lt;/h2&gt;

&lt;p&gt;Metric learning approaches aim to learn a distance metric that assigns smaller
distances between similar pairs, and larger distances between dissimilar pairs.
Collaborative Metric Learning (CML) &lt;a class=&quot;citation&quot; href=&quot;#cml&quot;&gt;[9]&lt;/a&gt; advocates the embedding of users
and items for recommender systems in &lt;em&gt;metric spaces&lt;/em&gt; in order to exploit a
phenomenon called &lt;em&gt;similarity propagation&lt;/em&gt;. In their work, Hsieh et al.
&lt;a class=&quot;citation&quot; href=&quot;#cml&quot;&gt;[9]&lt;/a&gt; explain how &lt;em&gt;similarity propagation&lt;/em&gt; is achieved 
due to the fact that a distance metric $d$ must respect, amongst several other conditions, 
the crucial triangle-inequality:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\forall x,y,z\colon
\quad
d(y,z)\leq d(x,y) + d(x,z).&lt;/script&gt;

&lt;p&gt;This implies that, given the information that “$x$ is similar to both $y$ and
$z$” the learned metric $d$ will not only pull the pairs $y$ and $z$ close to
$x$, but &lt;em&gt;also&lt;/em&gt; pull $y$ and $z$ relatively close to one-another. Thus, the
similarity of $(x,y)$ and $(x,z)$ is &lt;em&gt;propagated&lt;/em&gt; to $(y,z)$.&lt;/p&gt;

&lt;p&gt;The authors critique that, since matrix factorization is using the
inner-product, and the inner-product does not necessarily respect the
triangle inequality (e.g., violation for $x=-1$, $y=z=1$), such a &lt;em&gt;similarity
propagation&lt;/em&gt; is not happening in matrix factorization approaches.
An illustration of how the inner-product fails at propagating similarities
even for a simple interaction matrix is given below:&lt;/p&gt;

&lt;div class=&quot;figure-with-caption&quot;&gt;
&lt;img src=&quot;/img/2019-12-16-An-Overview-of-Collaborative-Filtering-Algorithms/cml-similarity-propagation-illustration.png?v=1&quot; alt=&quot;CML Similarity Propagation Illustration&quot; width=&quot;100%&quot; /&gt;
&lt;div class=&quot;figure-caption&quot;&gt;
Illustration by &lt;a class=&quot;citation&quot; href=&quot;#cml&quot;&gt;[9]&lt;/a&gt; showing how the inner-product
fails at propagating similarities. In the example $U_3$ likes both, $v_1$ and
$v_2$. Since $U_1$ likes $v_1$ and $U_2$ likes $v_2$ the items $v_1$ and
$v_2$ are placed in-between the users in the metric-learning approach. With
matrix factorization the dot-product is 2 if a user liked an item and 0
otherwise, representing a stable setting. However, the similarity between
$(U_3,v_1)$ and $(U_3,v_2)$ is not propagated to $(v_1,v_2)$ because we have that
$\scprod{v_1,v_2}=0$. Even though MF may yield the same recommendation
performance, the similarities between the items $v_1$ and $v_2$ aren't
obtained as well as with the metric learning approach.
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;The great convenience of encoding users and items in a metric space $(\cM,d)$ is
that the joint metric space does not only encode the similarity between users
and items, but it can also be used to determine user-user and item-item
similarities. This improves the interpretability of the model, as opposed to a
model that relies on the inner product to compute similarities. What matrix
factorization approaches usually do to compensate for this lack is to compute
user-user or item-item similarities using the cosine-distance.
However as illustrated in the figure above, this doesn’t yield optimal results.&lt;/p&gt;

&lt;p&gt;Hopefully, by now the reader should be convinced that &lt;em&gt;similarity propagation&lt;/em&gt; 
is a desirable property to have in order to generalize from the observed user-item 
interactions to unseen pairs of interactions and user-user and item-item similarities.
Next, we’ll look at how the training of the embeddings is performed in CML.&lt;/p&gt;

&lt;p&gt;The embedding training approach of of CML is to pull positive user-item
pairs close together and to push negative user-item pairs far apart according
to some margin. This process will then cluster users who co-like the same items 
together, and also cluster the items that are co-liked by the same users together. 
Eventually, a situation is reached where the nearest neighbours of any user will become:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;the items he liked, and&lt;/li&gt;
  &lt;li&gt;the items liked by other users who share a similar taste with this user.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Therefore, learning from the observed positive interactions
&lt;em&gt;propagates&lt;/em&gt; these relationships also to user-user and item-item pairs for
which there are &lt;em&gt;no&lt;/em&gt; observed relationships.&lt;/p&gt;

&lt;p&gt;In CML the relevances then are simply predicted as the negative distance&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{x}_{ui}=-d(\vx_u,\vx_i),&lt;/script&gt;

&lt;p&gt;meaning that a closeby item as a higher ranking than an item that is farther away.
The optimization objective trained to achieve the aforementioned desiderata
is the following:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\cL(\vtheta)
=
\cL_m(\vtheta)
+
\lambda\Omega(\vtheta)
\quad \text{s.t. }
\norm{\vx_*}\leq 1,&lt;/script&gt;

&lt;p&gt;where the various loss terms have the following meanings:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The term $\cL_m(\vtheta)$ is the WARP loss of the predicted rankings, given
by the negative metric space distances $\hat{x}_{ui}=-d(\vx_u,\vx_i)$ and 
$\hat{x}_{uj}=-d(\vx_u,\vx_j)$:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\cL_m(\vtheta)=\sum_{(i,j)\in\cS}\sum_{(u,k)\nin\cS}
w_{ij}\left[m+d(\vx_u,\vx_i)^2-d(\vx_u,\vx_j)^2\right]_+.&lt;/script&gt;

    &lt;p&gt;The set $\cS$ is the set of observed positive interactions. The gradients caused
by the WARP loss for a user $u$ and its positive and negative items are
illustrated in the figure below.&lt;/p&gt;

    &lt;div class=&quot;figure-with-caption&quot;&gt;
&lt;img src=&quot;/img/2019-12-16-An-Overview-of-Collaborative-Filtering-Algorithms/cml-positive-and-negative-item-gradients.png?v=1&quot; alt=&quot;CML Gradients&quot; width=&quot;100%&quot; /&gt;
&lt;div class=&quot;figure-caption&quot;&gt;
The figure by &lt;a class=&quot;citation&quot; href=&quot;#cml&quot;&gt;[9]&lt;/a&gt; shows the gradients created by the WARP loss
in CML. For the positive items of a user, gradients are created to pull them closer
until they lie within a certain margin $m$ to the user. For the negative items of a 
user, gradients are created to push them away until they lie far away from the user,
outside a ball of radius $m$, where $m$ is the margin, usually chosen as $1$.
&lt;/div&gt;
&lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The regularization term $\Omega(\vtheta)$ uses &lt;em&gt;covariance
regularization&lt;/em&gt; as proposed by Cogswell et al. &lt;a class=&quot;citation&quot; href=&quot;#cogswell2015reducing&quot;&gt;[34]&lt;/a&gt;.&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\Omega(\vtheta)=\norm{\MSigma - \diag(\MSigma)}_2^2,&lt;/script&gt;

    &lt;p&gt;where $\MSigma$ is the covariance matrix of the concatenation of all the user
and item embeddings.
This de-correlates the dimensions of the metric space. Since covariances can
be seen as a measure of linear redundancy between dimensions, this loss
essentially tries to prevent each dimension from being redundant by penalizing
off-diagonal entries in the covariance matrix and thus encouraging the
embeddings to efficiently utilize the given space.
The covariance matrix is computed as follows: Let $\MY$ be the concatenation
of the $d$-dimensional user and item-embeddings $\MX_U$ and $\MX_I$:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\MY=\begin{bmatrix}
\MX_U\\
\MX_I
\end{bmatrix}
\in\R^{(\card{U}+\card{I})\times d}.&lt;/script&gt;

    &lt;p&gt;The mean embedding vector is then computed as&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\vmu
:=
\frac{1}{\card{U}+\card{I}}\sum_{i=1}^{\card{U}+\card{I}}
\MY_{i,:}\in\R^{1\times d},&lt;/script&gt;

    &lt;p&gt;and the covariance matrix $\MSigma$ is obtained via&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\MSigma
=
\frac{1}{\card{U}+\card{I}}
\sum_{i=1}^{\card{U}+\card{I}}
\left(\MY_{i,:}-\vmu\right)^\T
\left(\MY_{i,:}-\vmu\right)\in\R^{d\times d}.&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The optimization constraint $\norm{\vx_{*}}\leq 1$ forces all user and
item embeddings $\vx_{*}$ to stay within a unit-sphere in order to easily
apply locality sensitive hashing (LSH) &lt;a class=&quot;citation&quot; href=&quot;#lsh1&quot;&gt;[16]&lt;/a&gt; later. L2-regularization is
intentionally avoided, as this would just pull the embeddings towards the
origin. The authors argue that in the metric space the origin does not have
any specific meaning.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;One great advantage of CML is that it can the recommendations can be easily 
performed on massive datasets. Since CML uses the Euclidean distance to 
represent the relevances, it can be used with off-the-shelf LSH. In contrast, matrix 
factorization approaches would have to use approximate Maximum Inner Product Search 
(MIPS), which is considered to be a much harder problem than LSH &lt;a class=&quot;citation&quot; href=&quot;#mips&quot;&gt;[15]&lt;/a&gt;. A disadvantage of CML might be that the distance function itself might not be 
expressive enough to represent the complex user-item relevance relationships,
which might be modeled through arbitrary non-linear interaction functions as
suggested in some approaches that follow later.&lt;/p&gt;

&lt;p&gt;Still, the example of CML clearly illustrated the benefits obtained through
&lt;em&gt;similarity propagation&lt;/em&gt; when learning a distance metric to predict the
relevances. This also motivates the next recommender system approaches, which also
learn distance metrics in hyperbolic space to predict rankings.&lt;/p&gt;

&lt;h2 id=&quot;hyperbolic-recommender-systems&quot;&gt;Hyperbolic Recommender Systems&lt;/h2&gt;

&lt;p&gt;So far, three approaches &lt;a class=&quot;citation&quot; href=&quot;#hrs&quot;&gt;[35, 36, 37]&lt;/a&gt; harnessing 
hyperbolic geometry for recommender systems have been published. Both approaches represent users and
items in hyperbolic geometry and predict the relevance between users and items as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\hat{x}_{ui}=\alpha d(\vx_u,\vx_i),\quad\text{with }\alpha&lt;0, %]]&gt;&lt;/script&gt;

&lt;p&gt;where $\vx_u$ and $\vx_i$ are the trained user and item-embeddings, lying in
hyperbolic geometry, and $d$ is the geodesic distance function in hyperbolic
geometry.&lt;/p&gt;

&lt;p&gt;Since all approaches use distance
metrics to represent the relevance relationships between users and items they all 
fall under the category of &lt;em&gt;metric learning approaches&lt;/em&gt;, just as the aforementioned
CML. Therefore, they also benefit from the &lt;em&gt;similarity propagation&lt;/em&gt; phenomenon, as
the hyperbolic geodesic distance also has to respect the triangle inequality.&lt;/p&gt;

&lt;p&gt;The approaches of &lt;a class=&quot;citation&quot; href=&quot;#hrs&quot;&gt;[35, 36, 37]&lt;/a&gt; train their embeddings via 
the BPR loss &lt;a class=&quot;citation&quot; href=&quot;#rendle2009bpr&quot;&gt;[32]&lt;/a&gt;, yielding the optimization objective&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\cL(\vtheta)
=
\sum_{(u,i,j)}
-\log\left(\sigma\left(
\alpha\left(
d(\vx_u,\vx_i)-d(\vx_u,\vx_j)
\right)\right)\right),&lt;/script&gt;

&lt;p&gt;where the parameters $\vtheta$ consist of the user embeddings $\MX_U$, the item
embeddings $\MX_I$ and the scalar $\alpha$. In some of their experiments 
&lt;a class=&quot;citation&quot; href=&quot;#shrs&quot;&gt;[36]&lt;/a&gt; also use the WMBR &lt;a class=&quot;citation&quot; href=&quot;#liu2017wmrb&quot;&gt;[38]&lt;/a&gt; 
loss. The embeddings are trained via the Riemannian optimization used with hyperbolic spaces. 
An illustration of the architecture of the &lt;em&gt;pairwise learning approach&lt;/em&gt; is given in the figure 
below.&lt;/p&gt;

&lt;div class=&quot;figure-with-caption&quot;&gt;
&lt;img src=&quot;/img/2019-12-16-An-Overview-of-Collaborative-Filtering-Algorithms/hrs.png?v=1&quot; alt=&quot;Pairwise Learning in Hyperbolic Recommender System&quot; width=&quot;100%&quot; /&gt;
&lt;div class=&quot;figure-caption&quot;&gt;
Illustration of the pairwise learning approach with hyperbolic recommender systems
by &lt;a class=&quot;citation&quot; href=&quot;#hrs&quot;&gt;[35]&lt;/a&gt;.
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Even though Vinh et al. &lt;a class=&quot;citation&quot; href=&quot;#hrs&quot;&gt;[35]&lt;/a&gt; use the Poincaré ball, and
Chamberlain et al. &lt;a class=&quot;citation&quot; href=&quot;#shrs&quot;&gt;[36]&lt;/a&gt; use the hyperboloid as their model for
hyperbolic geometry, the two approaches can be considered as practically
equivalent. The only real difference is that Chamberlain et al. further apply
some L2-regularization on the user and item embeddings.&lt;/p&gt;

&lt;p&gt;Chamberlain et al. &lt;a class=&quot;citation&quot; href=&quot;#shrs&quot;&gt;[36]&lt;/a&gt; further explored the 
possibilities of expressing users as the Einstein midpoint $\vmu$ (corresponding to a mean) 
of their positively interacted items in order to reduce the amount of learned parameters:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\vx_u:=\vmu(\dset{i\in I}{u \text{ has positively interacted with }i}).&lt;/script&gt;

&lt;p&gt;In their experiments, Chamberlain et al. showed that expressing the users as the
midpoint of their interacted items can speed-up the training, due to the
reduced amount of parameters, without sacrificing the model’s recommendation
performance. Such an approach is particularly useful for &lt;em&gt;asymmetric&lt;/em&gt; datasets that contain
much more users than items ($\card{U}\gg\card{I}$).&lt;/p&gt;

&lt;p&gt;The third hyperbolic recommender system approach of Schmeier et al. &lt;a class=&quot;citation&quot; href=&quot;#bhrs&quot;&gt;[37]&lt;/a&gt; embedded their entities using a different loss&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\cL(\vtheta)
=
-
\sum_{(u,i)\in\cD}
\log\left(
\frac{
e^{\hat{x}_{ui}}
}{
e^{\hat{x}_{ui}}
+
\sum_{(u,j)\in\cD'}
e^{\hat{x}_{uj}}
}
\right),&lt;/script&gt;

&lt;p&gt;where $\cD$ is the dataset of positive interactions and $\cD’$ is a set of $K$
negative interactions for user $u$, obtained through negative sampling. This loss 
also encourages that relevant user-item paris are closeby, and irrelevant 
user-item pairs are farther apart. Also, this is exactly the same loss that was used 
by Nickel &amp;amp; Kiela &lt;a class=&quot;citation&quot; href=&quot;#nickel2017poincare&quot;&gt;[39]&lt;/a&gt; to train a 
graph-embedding for the representation of hypernymy relations in hyperbolic space.&lt;/p&gt;

&lt;p&gt;To conclude, let’s discuss the advantages and disadvantages of these hyperbolic 
recommender models. The advantages of these metric learning approaches are the same as
the ones of CML: the most important one being that they all profit from similarity 
propagation and thus simultaneously learn user-user and item-item similarity. 
Furthermore, as revealed in the experiments of three approaches, the choice of a 
hyperbolic geometry turned out to provide a good bias for the representations.
One can also imagine that one could perform fast nearest-neighbour search for massive 
datasets through a generalization of LSH to hyperbolic space. Similarly as to CML,
these approaches have the disadvantage that the distance function might not be 
powerful enough to express the user-item relevance relationships entirely. It might be
that this relationship is even better modeled through a non-linear interaction function as 
suggested in the next approach.&lt;/p&gt;

&lt;h2 id=&quot;neural-collaborative-filtering-ncf&quot;&gt;Neural Collaborative Filtering (NCF)&lt;/h2&gt;

&lt;p&gt;In contrast to the bi-linear prediction function used with matrix factorization, or
a rigid distance function as used with the metric learning approaches, 
&lt;em&gt;Neural Collaborative Filtering (NCF)&lt;/em&gt;, introduced by He et al. 
&lt;a class=&quot;citation&quot; href=&quot;#ncf&quot;&gt;[33]&lt;/a&gt;, aims to learn a &lt;em&gt;non-linear interaction function&lt;/em&gt; 
acting on trained user and item embeddings to predict the relevances. The non-linear 
interaction function is implemented through two models that are trained jointly:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Generalized Matrix Factorization (GMF):&lt;/strong&gt;
  representing a generalization of the inner-product, where the products in
  the inner product are further scaled by individual factors.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Multi-Layer Perceptron (MLP):&lt;/strong&gt; a pyramidal 3-layer perceptron
  with ReLU activations.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The ranking $\hat{x}_{ui}$, representing the relevance of item $i\in I$ for
a user $u\in U$ is computed as follows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;First, the user and item embeddings, that are also learned, are retrieved 
for each of the two joint models:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\vx_u^{GMF}, \vx_i^{GMF},\qquad \vx_u^{MLP}, \vx_i^{MLP}.&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Then, the interaction for GMF is computed by building the
element-wise product of the corresponding user and item embedding vectors.
Then a weighted sum of the product’s coefficients is computed through a 
parameter $\vh$ and also a bias is added:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{x}_{ui}^{GMF}=\vh^T\left(\vx_u^{GMF}\odot \vx_i^{GMF}\right) +
b^{GMF}.&lt;/script&gt;

    &lt;p&gt;Note how for $\vh=(1,\ldots,1)^\T$ and $b^{GMF}=0$ the GMF model
recovers the usual dot-product that is used in matrix-factorization.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Then, the interaction for the MLP is computed by concatenating the
corresponding user and item embeddings and passing them
through the pyramidal 3-layer perceptron with ReLU activations. Also,
a bias is added:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{x}_{ui}^{MLP}=\text{MLP}(\vx_{u}^{MLP}, \vx_{i}^{MLP}) + b^{MLP}.&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In order to weigh the importance of both models, the results of GMF
and the 3-MLP may be scaled by factors $\alpha$ and $(1-\alpha)$, where
$\alpha\in(0,1)$. In their proposed architecture He et al. fixed
$\alpha=0.5$. Finally, the ranking $\hat{x}_{ij}$ is obtained by building a
convex combination of the activations $\hat{x}_{ui}^{GMF}$ and
$\hat{x}_{ui}^{MLP}$, and then and passing the result through the sigmoid
function:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{x}_{ui}=\sigma\left(
\alpha \hat{x}_{ui}^{GMF} + (1-\alpha)\hat{x}_{ui}^{MLP}
\right).&lt;/script&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;An illustration of the architecture of NCF is given in the figure below. The
models GMF and MLP can also be instantiated on their own, while the sigmoid
output function is maintained.&lt;/p&gt;

&lt;div class=&quot;figure-with-caption&quot;&gt;
&lt;img src=&quot;/img/2019-12-16-An-Overview-of-Collaborative-Filtering-Algorithms/ncf.png?v=1&quot; alt=&quot;Neural Collaborative Filtering (NCF)&quot; width=&quot;100%&quot; /&gt;
&lt;div class=&quot;figure-caption&quot; style=&quot;text-align:center&quot;&gt;
Architecture of NCF illustrated by &lt;a class=&quot;citation&quot; href=&quot;#ncf&quot;&gt;[33]&lt;/a&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;In their experiments He et al. trained NCF using the binary cross-entropy loss
with negative sampling. One could also use the pair-wise BPR loss to train the
model’s parameters, however, in their experiments He et al. observed better 
performance metrics with the binary cross-entropy loss and negative sampling:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\cL(\vtheta)=-\sum_{(u,i)\in\cD}
\left[x_{ui}\log(\hat{x}_{ui}) + (1-x_{ui})\log(1-\hat{x}_{ui})\right],&lt;/script&gt;

&lt;p&gt;where the training instances $(u,i)\in\cD$ consist of positive and
negative interactions. The negative interactions are oversampled according to a
negative sampling factor of $K$, where $K=5$ turned out to work well for both
datasets (Movielens-1M and Pinterest) for the datasets used in the experiments of He et al.&lt;/p&gt;

&lt;p&gt;While the models GMF and MLP can be instantiated each on their own, the
experiments of the He et al. &lt;a class=&quot;citation&quot; href=&quot;#ncf&quot;&gt;[33]&lt;/a&gt; revealed that the joint model
outperformed the individual models in every case. For the datasets
Movielens-1M and Pinterest, their proposed architecture outperformed a state-of-the-art 
matrix-factorization baseline eALS &lt;a class=&quot;citation&quot; href=&quot;#eals&quot;&gt;[22]&lt;/a&gt; (alternating 
least-squares MF). Thus, one can argue that modeling the interaction as a non-linear 
function, instead of a bi-linear function, is advantageous for the accurate prediction 
of rankings.&lt;/p&gt;

&lt;p&gt;The disadvantages of NCF are that, in contrast to the metric learning
approaches, NCF lacks interpretability and NCF does not automatically learn
user-user and item-item similarities via similarity propagation. 
Also, the rank prediction is rather computationally expensive and does not scale 
well to predictions over the the full set of items if one should desire to do so.
Also, techniques like LSH and MIPS cannot be applied to its embeddings or latent 
representations to get fast nearest-neighbour search.  However, for massive datasets it 
may still be used in conjunction with a retrieval system.&lt;/p&gt;

&lt;h2 id=&quot;autoencoders-for-collaborative-filtering&quot;&gt;Autoencoders for Collaborative Filtering&lt;/h2&gt;

&lt;p&gt;Recently, autoencoders have gained momentum in the field of recommender systems.
The important connection to be noticed here is that a 1-layer autoencoder with
linear activation functions reduces to the problem of &lt;em&gt;matrix factorization&lt;/em&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\cL(\vtheta)=\norm{\MX-\MD\MC\MX}_2^2,&lt;/script&gt;

&lt;p&gt;where the original interaction matrix $\MX$ is approximated through a
low-dimensional approximation of the original interaction matrix $\MX$.&lt;/p&gt;

&lt;p&gt;So, in some sense, general autoencoder approaches can be seen as
&lt;em&gt;non-linear matrix factorization&lt;/em&gt;, where the interaction matrix is
approximated through non-linear encoder and decoder functions, $C$ and $D$,
that are learned through optimizing the objective&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\cL(\vtheta)=\norm{\MX-D(C(\MX))}_2^2.&lt;/script&gt;

&lt;p&gt;One important advantage of these autoencoder approaches, assuming that they are
trained on user-interaction vectors, is that they can achieve &lt;em&gt;strong&lt;/em&gt;
generalization (as explained the work of &lt;a class=&quot;citation&quot; href=&quot;#liang2018variational&quot;&gt;[40]&lt;/a&gt;),
since they may do predictions for a user or item interaction vector that was not
observed at training time, whereas all the approaches that we have seen so far
always relied on having a pre-trained embedding vector for each user and item.&lt;/p&gt;

&lt;p&gt;Similarly as with matrix factorization, the major challenge in these autoencoder 
approaches is that for typical recommender system datasets the input vectors are 
&lt;em&gt;extremely sparse&lt;/em&gt;, inhibiting to get informative gradients 
&lt;a class=&quot;citation&quot; href=&quot;#strub2015collaborative&quot;&gt;[41]&lt;/a&gt;. One of the first papers 
applying autoencoders to collaborative filtering was the one by Sedhain et al., 
proposing the architecture Autorec&lt;a class=&quot;citation&quot; href=&quot;#sedhain2015autorec&quot;&gt;[42]&lt;/a&gt;. 
Autorec computes the reconstruction of an input
$\vx\in\R^d$, that can be either a user- or an item-interaction vector, via a
shallow autoencoder&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h(\vx;\vtheta)
=
f(\MW g(\MV\vx +\vmu)+\vb),&lt;/script&gt;

&lt;p&gt;where $f$ and $g$ are element-wise activation functions. The objective trained
to optimize Autorec’s parameters $\vtheta$ is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min_{\vtheta}\sum_{\vx\in\cS}^n\norm{\vx-h(\vx;\vtheta)}_{\cO}^2
+\frac{\lambda}{2}
(\norm{\MW}_F^2+\norm{\MV}_F^2),
\quad
\lambda &gt;0,&lt;/script&gt;

&lt;p&gt;where $\norm{\argdot}_{\cO}$ means that gradient-updates are only computed 
to parameters that are connected to the &lt;em&gt;observed&lt;/em&gt; entries of the interaction 
vector $\vx$. So, actually there exist two versions of Autorec: $U$-Autorec
and $I$-Autorec. They differ by the training examples that they consider:
$U$-Autorec uses user-interaction vectors $\cS_U=\set{\vx_u}_{u\in\U}$ and
$I$-Autorec uses item-interaction vectors $\cS_I=\set{\vx_i}_{i\in I}$. The
training/validation/test-split was done by doing a random 80%/10%/10%-split
of the interactions. In the case of $I$-Autorec, the prediction of the
relevance of item $i$ for a a user $u$ is done through&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{x}_{ui}=(h(\vx_i))_u.&lt;/script&gt;

&lt;p&gt;The architecture and gradient-updates with $I$-Autorec are illustrated in
the following picture.&lt;/p&gt;

&lt;div class=&quot;figure-with-caption&quot;&gt;
&lt;img src=&quot;/img/2019-12-16-An-Overview-of-Collaborative-Filtering-Algorithms/autorec.png?v=1&quot; alt=&quot;Architecture of Autorec&quot; width=&quot;100%&quot; /&gt;
&lt;div class=&quot;figure-caption&quot;&gt;
Illustration of the item-based architecture of $I$-Autorec. The edges (parameters)
that are connected to unknown interactions are not updated due to the masking of the loss
(affected edges marked in gray).
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;In their experiments, Sedhain et al. noticed that $I$-Autorec performed better
than $U$-Autorec and argued that this had to do with the fact that, in their
considered datasets, the item-interaction vectors were denser than the
user-interaction vectors, leading to more reliable predictions. While they do
not state this explicitly, one may also believe that using the denser
item-interaction vectors also leaded to more and better gradients, since more
inputs are non-zero. In Sedhain et al.’s experiments Autorec outperformed
classical matrix factorization methods, motivating the use of autoencoders.
Preliminary experiments also revealed that deeper autoencoders perform better.&lt;/p&gt;

&lt;p&gt;The paper from Strub &amp;amp; Mary &lt;a class=&quot;citation&quot; href=&quot;#strub2015collaborative&quot;&gt;[41]&lt;/a&gt; then was one of the
first autoencoder approaches for collaborative filtering to explicitly state the
sparsity problem and to concretely tackle it with an approach. Strub &amp;amp; Mary
also trained a loss similar to the masked squared reconstruction loss as Sedhain
et al., with two important differences:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;They did not just consider the reconstruction error, but the
&lt;em&gt;prediction&lt;/em&gt; error for a held-out item, therefore changing the
reconstruction target by the additional target item entry.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;They applied masking noise to the input interaction vectors to
have the autoencoder learn to reconstruct interactions.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In their experiments, Strub &amp;amp; Mary also showed that autoencoders can
outperform state-of-the-art recommender baselines.&lt;/p&gt;

&lt;p&gt;Inspired by $I$-Autorec &lt;a class=&quot;citation&quot; href=&quot;#sedhain2015autorec&quot;&gt;[42]&lt;/a&gt; and the approach of Strub &amp;amp;
Mary &lt;a class=&quot;citation&quot; href=&quot;#strub2015collaborative&quot;&gt;[41]&lt;/a&gt;, Kuchaiev &amp;amp; Ginsburg
&lt;a class=&quot;citation&quot; href=&quot;#kuchaiev2017training&quot;&gt;[43]&lt;/a&gt; from NVIDIA came along with further improvements and
another solution to tackle the sparsity problem. Kuchaiev &amp;amp; Ginsburg used a
technique called &lt;em&gt;dense re-feeding&lt;/em&gt; to deal with the the natural sparsity
of the interaction vectors.
With dense re-feeding the output $h(\vx)$, that is considered to be denser since
it is a probability-distribution, is re-fed to the autoencoder as an input, and
is just re-considered as a new training example with the same original target. Their
argument for using $h(\vx)$ again
as an input is that $h(\vx)$ should represent a &lt;em&gt;fixed-point&lt;/em&gt; of the
autoencoder: $h(h(\vx))=h(\vx)$. Kuchaiev &amp;amp; Ginsburg mention that the dense
re-feeding could be repeated several times, but they only applied it once.
A further improvement that Kuchaiev &amp;amp; Ginsburg did, is to use a time-based
training/validation/test-split, motivated by the fact that the recommender
system should predict future ratings from past ones, rather than randomly
missing ratings (as opposed to the splits used in
&lt;a class=&quot;citation&quot; href=&quot;#sedhain2015autorec&quot;&gt;[42, 41]&lt;/a&gt;).
In their experiments, Kuchaiev &amp;amp; Ginsburg observed that deeper autoencoders
with SELU activation functions and a high dropout-rate (e.g., 0.8), where dropout
is only used on the latent representation, trained together with dense
re-feeding performed the best. An important remark here is that one should not
apply dropout on the initial layer, as happening with the masking noise of Strub
&amp;amp; Mary, if one does not want the recommender system to learn to predict
&lt;em&gt;any&lt;/em&gt; random missing rating (e.g., correlations between items), but rather
a &lt;em&gt;future&lt;/em&gt; rating.&lt;/p&gt;

&lt;p&gt;Recently, Liang et al. from Netflix &lt;a class=&quot;citation&quot; href=&quot;#liang2018variational&quot;&gt;[40]&lt;/a&gt; came along and
extended variational autencoders (VAEs) to collaborative filtering. Their
generative model uses a multinomial likelihood, with the motivation that is
better-suited for modeling implicit feedback data, since it is a closer proxy to
the ranking loss compared to the more popular likelihood functions such as the
multivariate Gaussian (induced by squared loss) and logistic loss.&lt;/p&gt;

&lt;p&gt;The entire VAE architecture is then given by the encoder $g_{\phi}$ and decoder $f_{\theta}$ as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\vx_u
\stackrel{g_{\phi}}{\mapsto}
(\mu_{\phi}(\vx_u),\sigma_{\phi}(\vx_u))
\stackrel{\epsilon\sim\cN(\vo,\MI)}{\mapsto}
\vz_u=\vmu_{\phi}(\vx_u)+\epsilon\odot\vsigma_{\phi}(\vx_u)
\stackrel{f_{\theta}}{\mapsto}
\hat{\vx}_u,&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\pi(\vz_u)\propto\exp(f_{\theta}(\vz_u)),
\quad
\hat{\vx}_u\sim Mult(N_{u},\pi(\vz_{u})),&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\log\left(\cDist{p_{\theta}}{\hat{\vx}_{u}}{\vz_u}\right)
=
\sum_{i=1}^{\card{I}}x_{ui}\log(\pi_i(\vz_u)).&lt;/script&gt;

&lt;p&gt;The VAE is trained by annealing the evidence lower bound (ELBO)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\cL_{\beta}(\theta,\phi)
=
\sum_{\vx_u}\left[
\Exp[
\cDist{q_{\phi}}{\vz_u}{\vx_u}
]{\log\left(
\cDist{p_{\theta}}{\hat{\vx}_u}{\vz_u}
\right)}
-\beta
KL\left(
\cDist{q_{\phi}}{\vz_u}{\vx_u}
||
p(\vz_u)
\right)
\right],&lt;/script&gt;

&lt;p&gt;where $\beta$ is chosen to be $\beta&amp;lt;1$, relaxing the prior constraint
that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{1}{\card{U}}\sum_{u\in
U} \cDist{q_{\phi}}{\vz_u}{\vx_u} \approx p(\vz)=\cN(\vz;\vo,\MI)&lt;/script&gt;

&lt;p&gt;and sacrificing the ability to good ancestral sampling. Anyways, Kuchaiev &amp;amp;
Ginsburg argue that ancestral sampling is not needed in collaborative filtering.
Therefore, the prediction is simply performed by using the mean
$\mu_{\phi}(\vx_u)$ in the forward propagation, without any sampling of
$\epsilon$, giving&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{\vx}_u=f_{\theta}(\vmu_{\phi}(\vx_u)).&lt;/script&gt;

&lt;p&gt;In their experiments Liang et al. showed that the Multinomial likelihood yields
slightly better results than the Gaussian and the logistic likelihood. Further,
they showed that their architecture outperforms several state-of-the-art
baselines.&lt;/p&gt;

&lt;p&gt;Let us conclude the presentation of autoencoders for collaborative filtering
with two properties that all autoencoder approaches have in common: One
advantage of all autoencoder approaches is that they do not need any negative
sampling. One major disadvantage of all the autoencoder approaches is that,
inherently, depending on whether they are item-based or user-based, they either
predict the relevance of all $\card{I}$ items for a user, or the relevance
to all $\card{U}$ users of an item. This means that the input/output dimensions of
the autoencoders are always at least $\min(\card{U},\card{I})$. Thus, they do
not scale to datasets with a massive amount of users and items. Also,
their latent representations are hard to interpret and it’s not clear how
to perform efficient nearest-neighbour searches as one could do with LSH.&lt;/p&gt;

&lt;h2 id=&quot;summary-of-presented-collaborative-filtering-approaches&quot;&gt;Summary of Presented Collaborative Filtering Approaches&lt;/h2&gt;

&lt;p&gt;Let’s recap on a high-level what the various recommender system approaches do in
order to generalize to recommendations on unseen interactions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Item Popularity:&lt;/strong&gt; recommends items based on their popularity. The hope is
that the prediction through the popularity of items generalizes to the relevances of unseen 
user-item pairs.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Matrix Factorization:&lt;/strong&gt; learns embeddings that are fed through a &lt;em&gt;bi-linear&lt;/em&gt; interaction 
function, the dot product, to predict the rankings. The hope is that the dot-product of 
embedding vectors of unseen user-item pairs generalizes to the true relevances.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Metric Learning Approaches:&lt;/strong&gt; learn user and item embeddings in a metric spaces such 
that the distance is correlated with the relevance between users and items. Using a distance
metric allows to exploit the phenomenon of &lt;em&gt;similarity propagation&lt;/em&gt;. The hope is that 
the distances between the learned embeddings generalize to the true distances between unseen 
user-item pairs.
    &lt;ul style=&quot;margin-top:5px; margin-bottom: 5px&quot;&gt;
  &lt;li&gt;&lt;b&gt;Collaborative Metric Learning:&lt;/b&gt; uses Euclidean metric space&lt;/li&gt;
  &lt;li&gt;&lt;b&gt;Hyperbolic Recommender Systems:&lt;/b&gt; use hyperbolic metric spaces&lt;/li&gt;
&lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Neural Collaborative Filtering:&lt;/strong&gt; learns embeddings and the parameters of a &lt;em&gt;non-linear&lt;/em&gt; 
interaction function, that is a joint model of a shallow generalized matrix factorization and a 
pyramidal MLP, to predict the rankings. The hope is that the predictions of rankings through this 
non-linear interaction function with the learned embeddings generalize well for
unseen user-item pairs.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Autoencoder Approaches:&lt;/strong&gt; can be seen as &lt;em&gt;non-linear&lt;/em&gt; matrix factorization. They learn a 
&lt;em&gt;non-linear&lt;/em&gt; mapping from user (or item) interaction vectors to a latent representation, or
distribution, from which other relevant items will be predicted through a &lt;em&gt;non-linear&lt;/em&gt;
decoding function that gives the relevances of, or a relevance-distribution
over, the items (or users for an item). The hope is that the encoding and decoding of (unseen)
interaction vectors gives the right relevance predictions for the yet unobserved entries.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;span id=&quot;mckinsey&quot;&gt;“How retailers can keep up with consumers.” https://www.mckinsey.com/industries/retail/our-insights/how-retailers-can-keep-up-with-consumers.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;goodwatercap&quot;&gt;“Understanding Spotify: Making Music Through Innovation.” https://www.goodwatercap.com/thesis/understanding-spotify, 2018.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;bennett2007netflix&quot;&gt;J. Bennett, S. Lanning, and others, “The netflix prize,” in &lt;i&gt;Proceedings of KDD cup and workshop&lt;/i&gt;, 2007, vol. 2007, p. 35.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;gomez2016netflix&quot;&gt;C. A. Gomez-Uribe and N. Hunt, “The netflix recommender system: Algorithms, business value, and innovation,” &lt;i&gt;ACM Transactions on Management Information Systems (TMIS)&lt;/i&gt;, vol. 6, no. 4, p. 13, 2016.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;koren2009matrix&quot;&gt;Y. Koren, R. Bell, and C. Volinsky, “Matrix factorization techniques for recommender systems,” &lt;i&gt;Computer&lt;/i&gt;, no. 8, pp. 30–37, 2009.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;koren2009bellkor&quot;&gt;Y. Koren, “The bellkor solution to the netflix grand prize,” &lt;i&gt;Netflix prize documentation&lt;/i&gt;, vol. 81, no. 2009, pp. 1–10, 2009.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;netflixblog&quot;&gt;“Netflix Recommendations: Beyond the 5 stars (Part 1).” https://medium.com/netflix-techblog/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429, 2012.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;hu2008collaborative&quot;&gt;Y. Hu, Y. Koren, and C. Volinsky, “Collaborative filtering for implicit feedback datasets,” in &lt;i&gt;2008 Eighth IEEE International Conference on Data Mining&lt;/i&gt;, 2008, pp. 263–272.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;cml&quot;&gt;C.-K. Hsieh, L. Yang, Y. Cui, T.-Y. Lin, S. Belongie, and D. Estrin, “Collaborative metric learning,” in &lt;i&gt;Proceedings of the 26th international conference on world wide web&lt;/i&gt;, 2017, pp. 193–201.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;adomavicius2011context&quot;&gt;G. Adomavicius and A. Tuzhilin, “Context-aware recommender systems,” in &lt;i&gt;Recommender systems handbook&lt;/i&gt;, Springer, 2011, pp. 217–253.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;oard1998implicit&quot;&gt;D. W. Oard, J. Kim, and others, “Implicit feedback for recommender systems,” in &lt;i&gt;Proceedings of the AAAI workshop on recommender systems&lt;/i&gt;, 1998, vol. 83.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;davidson2010youtube&quot;&gt;J. Davidson &lt;i&gt;et al.&lt;/i&gt;, “The YouTube video recommendation system,” in &lt;i&gt;Proceedings of the fourth ACM conference on Recommender systems&lt;/i&gt;, 2010, pp. 293–296.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;cheng2016wide&quot;&gt;H.-T. Cheng &lt;i&gt;et al.&lt;/i&gt;, “Wide &amp;amp; deep learning for recommender systems,” in &lt;i&gt;Proceedings of the 1st workshop on deep learning for recommender systems&lt;/i&gt;, 2016, pp. 7–10.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;kdtrees&quot;&gt;J. L. Bentley, “K-d trees for semidynamic point sets,” in &lt;i&gt;Proceedings of the sixth annual symposium on Computational geometry&lt;/i&gt;, 1990, pp. 187–197.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;mips&quot;&gt;A. Shrivastava and P. Li, “Asymmetric LSH (ALSH) for sublinear time maximum inner product search (MIPS),” in &lt;i&gt;Advances in Neural Information Processing Systems&lt;/i&gt;, 2014, pp. 2321–2329.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;lsh1&quot;&gt;A. Gionis, P. Indyk, R. Motwani, and others, “Similarity search in high dimensions via hashing,” in &lt;i&gt;Vldb&lt;/i&gt;, 1999, vol. 99, no. 6, pp. 518–529.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;lsh2&quot;&gt;S. Har-Peled, P. Indyk, and R. Motwani, “Approximate nearest neighbor: Towards removing the curse of dimensionality,” &lt;i&gt;Theory of computing&lt;/i&gt;, vol. 8, no. 1, pp. 321–350, 2012.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;lsh3&quot;&gt;M. Bawa, T. Condie, and P. Ganesan, “LSH forest: self-tuning indexes for similarity search,” in &lt;i&gt;Proceedings of the 14th international conference on World Wide Web&lt;/i&gt;, 2005, pp. 651–660.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;sarwar2000application&quot;&gt;B. Sarwar, G. Karypis, J. Konstan, and J. Riedl, “Application of dimensionality reduction in recommender system-a case study,” Minnesota Univ Minneapolis Dept of Computer Science, 2000.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;koren2008factorization&quot;&gt;Y. Koren, “Factorization meets the neighborhood: a multifaceted collaborative filtering model,” in &lt;i&gt;Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining&lt;/i&gt;, 2008, pp. 426–434.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;pan2008one&quot;&gt;R. Pan &lt;i&gt;et al.&lt;/i&gt;, “One-class collaborative filtering,” in &lt;i&gt;2008 Eighth IEEE International Conference on Data Mining&lt;/i&gt;, 2008, pp. 502–511.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;eals&quot;&gt;X. He, H. Zhang, M.-Y. Kan, and T.-S. Chua, “Fast matrix factorization for online recommendation with implicit feedback,” in &lt;i&gt;Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval&lt;/i&gt;, 2016, pp. 549–558.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;mnih2008probabilistic&quot;&gt;A. Mnih and R. R. Salakhutdinov, “Probabilistic matrix factorization,” in &lt;i&gt;Advances in neural information processing systems&lt;/i&gt;, 2008, pp. 1257–1264.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;alswr&quot;&gt;Y. Zhou, D. Wilkinson, R. Schreiber, and R. Pan, “Large-scale parallel collaborative filtering for the netflix prize,” in &lt;i&gt;International conference on algorithmic applications in management&lt;/i&gt;, 2008, pp. 337–348.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;koren2009collaborative&quot;&gt;Y. Koren, “Collaborative filtering with temporal dynamics,” in &lt;i&gt;Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining&lt;/i&gt;, 2009, pp. 447–456.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;xiong2010temporal&quot;&gt;L. Xiong, X. Chen, T.-K. Huang, J. Schneider, and J. G. Carbonell, “Temporal collaborative filtering with bayesian probabilistic tensor factorization,” in &lt;i&gt;Proceedings of the 2010 SIAM international conference on data mining&lt;/i&gt;, 2010, pp. 211–222.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;luo2014efficient&quot;&gt;X. Luo, M. Zhou, Y. Xia, and Q. Zhu, “An efficient non-negative matrix-factorization-based approach to collaborative filtering for recommender systems,” &lt;i&gt;IEEE Transactions on Industrial Informatics&lt;/i&gt;, vol. 10, no. 2, pp. 1273–1284, 2014.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;gu2010collaborative&quot;&gt;Q. Gu, J. Zhou, and C. Ding, “Collaborative filtering: Weighted nonnegative matrix factorization incorporating user and item graphs,” in &lt;i&gt;Proceedings of the 2010 SIAM international conference on data mining&lt;/i&gt;, 2010, pp. 199–210.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;mairal2010online&quot;&gt;J. Mairal, F. Bach, J. Ponce, and G. Sapiro, “Online learning for matrix factorization and sparse coding,” &lt;i&gt;Journal of Machine Learning Research&lt;/i&gt;, vol. 11, no. Jan, pp. 19–60, 2010.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;dadkhahi2018alternating&quot;&gt;H. Dadkhahi and S. Negahban, “Alternating Linear Bandits for Online Matrix-Factorization Recommendation,” &lt;i&gt;arXiv preprint arXiv:1810.09401&lt;/i&gt;, 2018.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;wang2017factorization&quot;&gt;H. Wang, Q. Wu, and H. Wang, “Factorization bandits for interactive recommendation,” in &lt;i&gt;Thirty-First AAAI Conference on Artificial Intelligence&lt;/i&gt;, 2017.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;rendle2009bpr&quot;&gt;S. Rendle, C. Freudenthaler, Z. Gantner, and L. Schmidt-Thieme, “BPR: Bayesian personalized ranking from implicit feedback,” in &lt;i&gt;Proceedings of the twenty-fifth conference on uncertainty in artificial intelligence&lt;/i&gt;, 2009, pp. 452–461.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;ncf&quot;&gt;X. He, L. Liao, H. Zhang, L. Nie, X. Hu, and T.-S. Chua, “Neural collaborative filtering,” in &lt;i&gt;Proceedings of the 26th international conference on world wide web&lt;/i&gt;, 2017, pp. 173–182.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;cogswell2015reducing&quot;&gt;M. Cogswell, F. Ahmed, R. Girshick, L. Zitnick, and D. Batra, “Reducing overfitting in deep networks by decorrelating representations,” &lt;i&gt;arXiv preprint arXiv:1511.06068&lt;/i&gt;, 2015.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;hrs&quot;&gt;T. D. Q. Vinh, Y. Tay, S. Zhang, G. Cong, and X.-L. Li, “Hyperbolic recommender systems,” &lt;i&gt;arXiv preprint arXiv:1809.01703&lt;/i&gt;, 2018.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;shrs&quot;&gt;B. P. Chamberlain, S. R. Hardwick, D. R. Wardrope, F. Dzogang, F. Daolio, and S. Vargas, “Scalable Hyperbolic Recommender Systems,” &lt;i&gt;arXiv preprint arXiv:1902.08648&lt;/i&gt;, 2019.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;bhrs&quot;&gt;T. Schmeier, J. Chisari, S. Garrett, and B. Vintch, “Music recommendations in hyperbolic space: an application of empirical bayes and hierarchical poincaré embeddings,” in &lt;i&gt;Proceedings of the 13th ACM Conference on Recommender Systems&lt;/i&gt;, 2019, pp. 437–441.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;liu2017wmrb&quot;&gt;K. Liu and P. Natarajan, “WMRB: Learning to Rank in a Scalable Batch Training Approach,” &lt;i&gt;arXiv preprint arXiv:1711.04015&lt;/i&gt;, 2017.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;nickel2017poincare&quot;&gt;M. Nickel and D. Kiela, “Poincaré embeddings for learning hierarchical representations,” in &lt;i&gt;Advances in neural information processing systems&lt;/i&gt;, 2017, pp. 6338–6347.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;liang2018variational&quot;&gt;D. Liang, R. G. Krishnan, M. D. Hoffman, and T. Jebara, “Variational autoencoders for collaborative filtering,” in &lt;i&gt;Proceedings of the 2018 World Wide Web Conference&lt;/i&gt;, 2018, pp. 689–698.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;strub2015collaborative&quot;&gt;F. Strub and J. Mary, “Collaborative filtering with stacked denoising autoencoders and sparse inputs,” 2015.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;sedhain2015autorec&quot;&gt;S. Sedhain, A. K. Menon, S. Sanner, and L. Xie, “Autorec: Autoencoders meet collaborative filtering,” in &lt;i&gt;Proceedings of the 24th International Conference on World Wide Web&lt;/i&gt;, 2015, pp. 111–112.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;kuchaiev2017training&quot;&gt;O. Kuchaiev and B. Ginsburg, “Training deep autoencoders for collaborative filtering,” &lt;i&gt;arXiv preprint arXiv:1708.01715&lt;/i&gt;, 2017.&lt;/span&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>Andreas Bloch under the assistance of Octavian Ganea and Gary Bécigneul</name></author><category term="machine learning" /><category term="recommender systems" /><category term="collaborative filtering" /><category term="implicit feedback data" /><summary type="html">Recommender systems are at the heart of many of today's online platforms. Numerous approaches for collaborative filtering from implicit feedback data have been invented over the years. This blogpost provides an overview of several of these recommender algorithms.</summary></entry><entry><title type="html">A Universal Model for Hyperbolic, Euclidean and Spherical Geometries</title><link href="http://localhost:4000/K-Stereographic-Model/" rel="alternate" type="text/html" title="A Universal Model for Hyperbolic, Euclidean and Spherical Geometries" /><published>2019-11-21T20:00:00+01:00</published><updated>2019-11-21T20:00:00+01:00</updated><id>http://localhost:4000/K-Stereographic-Model</id><content type="html" xml:base="http://localhost:4000/K-Stereographic-Model/">&lt;p&gt;The Euclidean space is the default choice for representations in many of 
today’s machine learning tasks. Recent advances have also shown how a variety of 
tasks can further benefit from representations in (products of) spaces of constant 
curvature. The paper by Gu et al. &lt;a class=&quot;citation&quot; href=&quot;#gu2018learning&quot;&gt;[1]&lt;/a&gt; 
presents an approach that estimates and commits to the curvature of spaces in advance
and then learns embeddings the chosen (products of) spaces of constant curvature.&lt;/p&gt;

&lt;p&gt;In this blogpost we present a geometric model, called the &lt;strong&gt;$\kappa$-Stereographic Model&lt;/strong&gt;, 
that harnesses the formalism of gyrovector spaces in order to capture all three 
geometries of constant curvature (hyperbolic, Euclidean and spherical) at once. 
Furthermore, the presented model also allows to smoothly interpolate between the 
geometries of constant curvature and thus provides a way to learn the curvature of 
spaces jointly with the embeddings.&lt;/p&gt;

&lt;p&gt;The $\kappa$-stereographic model has been elaborated within the scope of the B.Sc. and M.Sc. 
theses of Andreas Bloch, Gregor Bachmann and Ondrej Skopek at the Data Analytics Lab of the 
ETH Zürich under the assistance of Octavian Ganea and Gary Bécigneul. Two papers
that apply the $\kappa$-stereographic model are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1911.08411&quot;&gt;
&lt;strong&gt;Mixed-curvature Variational Autoencoders&lt;/strong&gt;
&lt;/a&gt; 
&lt;a class=&quot;citation&quot; href=&quot;#skopek2019mixed&quot;&gt;[2]&lt;/a&gt; (ICLR 2020),&lt;br /&gt; 
Ondrej Skopek, Octavian Eugen Ganea, Gary Bécigneul&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1911.05076&quot;&gt;
&lt;strong&gt;Constant Curvature Graph Convolutional Networks&lt;/strong&gt;
&lt;/a&gt;
&lt;a class=&quot;citation&quot; href=&quot;#bachmann2019constant&quot;&gt;[3]&lt;/a&gt;,&lt;br /&gt; 
Gregor Bachmann, Gary Bécigneul, Octavian Eugen Ganea&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This blogpost aims to explain and illustrate the $\kappa$-stereographic
model in more detail. Also, it accompanies the 
&lt;a href=&quot;https://github.com/andbloch/geoopt/tree/universal-manifold/geoopt/manifolds /stereographic&quot;&gt;Pytorch implementation of the $\kappa$-stereographic model&lt;/a&gt; by 
Andreas Bloch. Many thanks here go to Maxim Kochurov whose Poincaré ball implementation 
provided an excellent starting point.&lt;/p&gt;

&lt;p&gt;We’ll start by first looking at the underlying algebraic structure of gyrovector
spaces. Then the formulas for the $\kappa$-stereographic model are given and the
interpolation between spaces of constant curvature is illustrated for a variety
of concepts. Finally, a code example using the $\kappa$-stereographic 
model is provided.&lt;/p&gt;

&lt;h2 id=&quot;models-for-spherical-and-hyperbolic-geometries&quot;&gt;Models for Spherical and Hyperbolic Geometries&lt;/h2&gt;

&lt;p&gt;Two common models for hyperbolic and spherical geometries are the hyperboloid
and the sphere. The formulas for these two model classes are very dual which 
can be observed for example in the formulas of the paper “Spherical and hyperbolic 
embeddings of data” &lt;a class=&quot;citation&quot; href=&quot;#wilson2014spherical&quot;&gt;[4]&lt;/a&gt;. 
One just has to switch a few signs and exchange the trigonometric 
functions with their hyperbolic variants in order to get the formulas for the 
hyperboloid from the ones of the sphere, and vice-versa. This explains why the 
hyperboloid is sometimes also referred to as the “&lt;em&gt;pseudosphere&lt;/em&gt;.”&lt;/p&gt;

&lt;p&gt;Two alternative models for hyperbolic and spherical geometries are the Poincaré 
ball and the stereographic projection of the sphere. Each of them result from 
the stereographic projection of the hyperboloid and the sphere, respectively, as
illustrated in the figures below:&lt;/p&gt;

&lt;table style=&quot;margin-bottom:0px; border: 0px;&quot;&gt;
&lt;tr style=&quot;border: 0px;&quot;&gt;
&lt;th style=&quot;text-align:center; border: 0px;&quot;&gt;Hyperboloid &amp;amp; Poincaré Ball &lt;/th&gt;
&lt;th style=&quot;text-align:center; border: 0px;&quot;&gt;Sphere &amp;amp; Stereographic Projection of Sphere&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:center; border: 0px;&quot;&gt;
&lt;img src=&quot;/img/2019-11-21-K-Stereographic-Model/hyperboloid-sproj.png?v=1&quot; width=&quot;70%&quot; /&gt;
&lt;/td&gt;
&lt;td style=&quot;text-align:center; border: 0px;&quot;&gt;
&lt;img src=&quot;/img/2019-11-21-K-Stereographic-Model/sphere-sproj.png?v=1&quot; width=&quot;90%&quot; /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;In this blogpost we show how the duality of the Poincaré ball and the stereographic
projection of the sphere can be captured within Ungar’s formalism of gyrovector 
spaces &lt;a class=&quot;citation&quot; href=&quot;#ungar2005analytic&quot;&gt;[5]&lt;/a&gt;. The reason 
that the &lt;em&gt;stereographic projections&lt;/em&gt; were chosen in the model that will be presented
in what follows is that they allow to smoothly interpolate between spaces of positive 
and spaces of negative curvature – this can be very useful to learn the curvatures of factors of
product spaces used to train embeddings, but more on that in a future blogpost on 
curvature learning in product spaces. For now, we just want to familiarize ourselves with 
gyrovector spaces and our concrete instantiation of a gyrovector space: the 
&lt;em&gt;$\kappa$-stereographic model&lt;/em&gt; for spherical, Euclidean and hyperbolic geometries.&lt;/p&gt;

&lt;h2 id=&quot;gyrovector-spaces&quot;&gt;Gyrovector Spaces&lt;/h2&gt;

&lt;p&gt;An important property of hyperbolic space is that it isn’t a vector space. To this 
end, Ungar introduced the algebraic structure of &lt;em&gt;gyrovector spaces&lt;/em&gt;
&lt;a class=&quot;citation&quot; href=&quot;#ungar1991thomas&quot;&gt;[6]&lt;/a&gt;, 
which have operations and properties
reminiscent of the ones of vector spaces. Indeed, gyrogroups and gyrovector spaces
are a generalization of groups and vector spaces. One great advantage of gyrovector spaces
is that with Ungar’s gyrovector space approach to hyperbolic geometry we get much 
more intuitive and concise formulas for things like geodesics, distances or 
the Pythagorean theorem in hyperbolic geometry.&lt;/p&gt;

&lt;!--
So far, gyrovector spaces have been mostly used to represent 
the hyperbolic geometry for the study of special relativity theory. In a recent
work of theirs, Ganea et al. &lt;a class=&quot;citation&quot; href=&quot;#hnn&quot;&gt;[7]&lt;/a&gt;
showed how one can harness the formalism of gyrovector spaces to implement the 
essential operations for deep neural networks that operate on hyperbolic representations. 
Throughout the development of our theses related to curvature learning, we discovered 
that the algebraic structure of a gyrovector space can also be instantiated to represent 
spherical geometries -- more on that in the next section. First, we want to familiarize 
ourselves with the abstract notion of gyrovector spaces.
--&gt;

&lt;p&gt;In what follows we present the most important definitions that give rise to
gyrovector spaces. The definitions presented here are taken from 
Ungar’s work &lt;a class=&quot;citation&quot; href=&quot;#ungar2001hyperbolic&quot;&gt;[8]&lt;/a&gt;, where 
the algebra’s axioms and and some of its deriveable properties are introduced 
jointly for convenience. For a presentation that restricts the definitions to a 
minimal set of axioms and then separately derivates the resulting properties the 
interested reader is referred to Ungar’s other work &lt;a class=&quot;citation&quot; href=&quot;#ungar2005analytic&quot;&gt;[5]&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;span class=&quot;def&quot;&gt;&lt;strong&gt;D. (Groupoid)&lt;/strong&gt;&lt;/span&gt; A &lt;em&gt;groupoid&lt;/em&gt; $(S, +)$ is a pair of a
nonempty set $S$ and a binary operation $+\colon S\times S\to S$.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;span class=&quot;def&quot;&gt;&lt;strong&gt;D. (Groupoid Automorphism)&lt;/strong&gt;&lt;/span&gt; An &lt;em&gt;automorphism&lt;/em&gt; $\phi$ of a groupoid $
(S,+)$
is a &lt;em&gt;bijective&lt;/em&gt; self-map of $S$ that respects its binary operation,&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;\forall s_1,s_2\in S
\colon
\quad
\phi(s_1 + s_2)
=
\phi(s_1) + \phi(s_2).&lt;/script&gt;
&lt;/blockquote&gt;

&lt;p&gt;In other words, the groupoid automorphism $\phi$ preserves the structure of the groupoid. 
Furthermore, the set of all automorphisms of a groupoid form a group:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;span class=&quot;def&quot;&gt;&lt;strong&gt;D. (Automorphism Group)&lt;/strong&gt;&lt;/span&gt; The set of all automorphisms of a
groupoid $(S,+)$ forms a group, denoted  as $\Aut(S,+)$.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now, we define a gyrogroup, which is an essential component of a gyrovector space.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;span class=&quot;def&quot;&gt;&lt;strong&gt;D. (Gyrogroup)&lt;/strong&gt;&lt;/span&gt; A groupoid $(G,\oplus)$ is a &lt;em&gt;gyrogroup&lt;/em&gt; 
if its binary operation satisfies the following axioms and properties. In $G$, there
exists a unique element, $0$, called the identity, satisfying&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;0\oplus a= a\oplus 0= a,
\qquad\text{additive identity},&lt;/script&gt;

  &lt;p&gt;for all $a\in G$. For each $a$ in $G$, there exists a unique invese $\ominus a$ in $G$,
satisfying&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;\ominus a \oplus a = a\ominus a = 0,\qquad\text{inverse},&lt;/script&gt;

  &lt;p&gt;where we use the notation $a\ominus b=a\oplus (\ominus b)$ for $a,b\in G$.
For any $a,b\in G$, the self-map $\gyr[a,b]$ of $G$ is given by the equation&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;\gyr[a,b]z =
\ominus(a\oplus b) \oplus (a \oplus (b\oplus z)),&lt;/script&gt;

  &lt;p&gt;for all $z\in G$. Furthermore, the following conditions hold for all $a,b,c\in
 G$:&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\gyr[a,b]&amp;\in \Aut(G,\oplus),
&amp;&amp; \text{gyroautomorphism property},
\\
a\oplus (b\oplus c) &amp;= (a \oplus b) \oplus \gyr[a,b]c,
&amp;&amp; \text{left gyroassociative law},
\\
(a\oplus b) \oplus c &amp;= a \oplus (b \oplus \gyr[b,a]c),
&amp;&amp; \text{right gyroassociative law},
\\
\gyr[a,b] &amp;= \gyr[a\oplus b, b],
&amp;&amp; \text{left loop property},
\\
\gyr[a,b] &amp;= \gyr[a, b\oplus a],
&amp;&amp; \text{right loop property},
\\
\ominus(a\oplus b) &amp;= \gyr[a,b](\ominus b\ominus a),
&amp;&amp; \text{gyrosum inversion law},
\\
\gyr^{-1}[a,b] &amp;= \gyr[b,a],
&amp;&amp; \text{gyroautomorphism inversion}.
\end{align*} %]]&gt;&lt;/script&gt;

  &lt;p&gt;The operation $\gyr\colon G\times G\to\Aut(G,\oplus)$ is called the &lt;em&gt;gyrator&lt;/em&gt; of $G$ and
the automorphism $\gyr[a,b]\colon G\to G$ is called the gyroautomorphism of $G$, generated by $a,
b\in G$.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;An important thing to note in the definition of the gyrogroup, is that if one was 
to leave out the gyrations in the definitions, one would get the properties of a 
group algebra. Indeed, if one instantiates the gyrogroup with vectors and vector 
addition, then the gyration becomes trivial and we end up with an algebra that 
has the properties of a group. Thus, the gyrogroup can be seen as a genralization of 
the group structure.&lt;/p&gt;

&lt;p&gt;Analogously to groups and gyrogroups, the commutativity for gyrogroups is defined as fllows:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;span class=&quot;def&quot;&gt;&lt;strong&gt;D. (Gyrocommutative Gyrogroup)&lt;/strong&gt;&lt;/span&gt; A gyrogroup is &lt;em&gt;gyrocommutative&lt;/em&gt;
if it satisfies&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;a \oplus b
=
\gyr[a,b](b\oplus a),
\qquad
\text{gyrocommutative law.}&lt;/script&gt;
&lt;/blockquote&gt;

&lt;p&gt;Some gyrocommutative gyrogroups admit scalar multiplication, turning them into
gyrovector spaces. Just as commutative groups with a scalar multiplication give rise
to vector spaces.&lt;/p&gt;

&lt;!--
make sure that &quot;subseteq&quot; (subset including) and not real subset (excluding) carrier
is meant. The book uses the real subset notation. But I think they mean &quot;subseteq&quot; with it.
This concerns the properties 1. and 3.
--&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;span class=&quot;def&quot;&gt;&lt;strong&gt;D. (Gyrovector Spaces)&lt;/strong&gt;&lt;/span&gt; A &lt;em&gt;real inner
product gyrovector space&lt;/em&gt; $(G,\oplus,\otimes)$ (gyrovector space, in short) is a 
gyrocommutative gyrogroup $(G,\oplus)$ that obeys the following axioms and properties:&lt;/p&gt;

  &lt;ol&gt;
    &lt;li&gt;
      &lt;p&gt;$G$ is a subset of a real inner product vector space $\bbV$ called the carrier of
$G$, $G\subseteq \bbV$, from which it inherits its inner product, $\scprod{\argdot,\argdot}$,
and norm, $\norm{\argdot}$, which are invariant under gyroautomorphisms, that is,&lt;/p&gt;

      &lt;script type=&quot;math/tex; mode=display&quot;&gt;\scprod{\gyr[\vu,\vv]\va,\gyr[\vu,\vv]\vb}=\scprod{\va,\vb},
\qquad\text{conformality}.&lt;/script&gt;
    &lt;/li&gt;
    &lt;li&gt;
      &lt;p&gt;$G$ admits a scalar multiplication, $\otimes$, possessing the following properties. For all
real numbers $r,r_1,r_2\in\R$, natural numbers $n\in\N$ and all points $\va,\vu,\vv\in G$:&lt;/p&gt;

      &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align*}
\\
1\otimes \va 
&amp;= 
\va,
&amp;&amp; \text{multiplicative identity},
\\
n\otimes \va 
&amp;= 
\va\oplus\cdots\oplus \va,
&amp;&amp; \text{gyroaddition }n\text{ times},
\\
(-r)\otimes\va  
&amp;= 
r \otimes (\ominus \va),
&amp;&amp; \text{sign distributivity},
\\
(r_1+r_2)\otimes\va 
&amp;= 
r_1\otimes \va\oplus r_2\otimes\va,
&amp;&amp;\text{scalar distributive Law},
\\
(r_1r_2)\otimes\va
&amp;=
r_1\otimes(r_2\otimes\va),
&amp;&amp;\text{scalar associative law},
\\
r\otimes(r_1\otimes\va\oplus r_2\otimes\va)
&amp;=
r\otimes(r_1\otimes\va)\oplus r\otimes(r_2\otimes\va),
&amp;&amp;\text{monodistributive law},
\\
\frac{\abs{r}\otimes\va}{\norm{r\otimes\va}}
&amp;=
\frac{\va}{\norm{\va}},
&amp;&amp;\text{scaling property},
\\
\gyr[\vu,\vv](r\otimes\va)
&amp;=
r\otimes\gyr[\vu,\vv]\va
&amp;&amp;\text{gyroautomorphism property},
\\
\gyr[r_1\otimes\va,r_2\otimes\va]
&amp;=
\id
&amp;&amp;\text{identity automorphism},
\\
\\
\end{align*} %]]&gt;&lt;/script&gt;
where we use the notation $r\otimes\va=\va\otimes r$.&lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
      &lt;p&gt;The algebra $(\norm{\G},\oplus,\otimes)$ for the set $\norm{G}$ of
one-dimensional “vectors”,&lt;/p&gt;

      &lt;script type=&quot;math/tex; mode=display&quot;&gt;\norm{G}=\dset{\norm{\va}}{\va\in G}\subseteq\R.&lt;/script&gt;

      &lt;p&gt;has a real vector space structure with vector addition $\oplus$ and scalar 
multiplication $\otimes$, such that for all $r\in\R$ and $\va,\vb\in G$,&lt;/p&gt;

      &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\norm{r\otimes\va}
&amp;=
\abs{r}\otimes\norm{\va},
&amp;&amp;\text{homogeneity property},
\\
\norm{\va\oplus\vb}
&amp;\leq
\norm{\va}\oplus\norm{\vb},
&amp;&amp;\text{gyrotriangle property},
\end{align*} %]]&gt;&lt;/script&gt;

      &lt;p&gt;connecting the addition and scalar multiplication of $G$ and $\norm{G}$.&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;From the definition of above, one can easily verify that $(-1)\otimes\va=\ominus\va$, and 
$\norm{\ominus\va}=\norm{\va}$. One should also note that the ambiguous use of $\oplus$ and 
$\otimes$ as interrelated operations in the gyrovector space $(G,\oplus,\otimes)$ and its 
associated one-dimensional “vector” space $(\norm{G},\oplus,\otimes)$ should not raise any 
confusion, since the sets in which these operations operate are always clear from the context. 
E.g., in vector spaces we also use the same notation, $+$, for the addition operation between 
vectors and between their magnitudes, and the same notation for the scalar multiplication between
 two scalars and between a scalar and a vector.&lt;/p&gt;

&lt;p&gt;However, it’s important to note that the operations in the gyrovector space
$(G,\oplus,\otimes)$ are nonassociative-nondistributive gyrovector space operations, and the
operations in $(\norm{G},\oplus,\otimes)$ are associative-distributive vector space
operations. Additionally, the gyro-addition $\oplus$ is gyrocommutative in the former, and 
commutative in the latter. Also note that in the vector space $(\norm{G},\oplus,\otimes)$ the
gyrations are trivial.&lt;/p&gt;

&lt;p&gt;Next, we’ll look at how we can use the algebraic structure of a gyrovector space to
implement one universal model, able to capture hyperbolic, spherical and Euclidean 
geometries.&lt;/p&gt;

&lt;h2 id=&quot;the-kappa-stereographic-model-for-hyperbolic-spherical-and-euclidean-geometry&quot;&gt;The $\kappa$-Stereographic Model for Hyperbolic, Spherical and Euclidean Geometry&lt;/h2&gt;

&lt;p&gt;In their paper about “Hyperbolic neural networks” &lt;a class=&quot;citation&quot; href=&quot;#hnn&quot;&gt;[7]&lt;/a&gt;,
Ganea et al. already showed how one can harness the gyrovector space formalism 
presented by Ungar in &lt;a class=&quot;citation&quot; href=&quot;#ungar2005analytic&quot;&gt;[5]&lt;/a&gt; to 
implement all the necessary tools for deep neural networks that operate on 
hyperbolic representations. Later, throughout the development of our theses related 
to curvature-learning, we discovered and verified that one can use the same gyrovector 
space formalism also with &lt;em&gt;positive&lt;/em&gt; sectional 
curvature in order to also implement all of the necessary operations for the model of the 
stereographic projection of the sphere.&lt;/p&gt;

&lt;p&gt;For some $n$-dimensional manifold with constant sectional curvature 
$\kappa\in\R$, we can instantiate a corresponding gyrovector space algebra 
$(\cM_\kappa^n,\oplus_\kappa,\otimes_\kappa)$, to intuitively express
and compute important operations on the manifold in closed form. The concrete definitions 
of the carrier set and operations for the gyrovector space algebra 
$(\cM_\kappa^n,\oplus_\kappa,\otimes_\kappa)$ are given in what follows.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;span class=&quot;def&quot;&gt;&lt;strong&gt;D. (Carrier Set)&lt;/strong&gt;&lt;/span&gt; The &lt;em&gt;carrier set&lt;/em&gt; $\cM_\kappa^n$ of an
$n$-dimensional gyrovector space, corresponding to a manifold of constant sectional 
curvature $\kappa$, is defined as:&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\cM_\kappa^n
=
\dset{\vx\in\R^n}{-\kappa\norm{\vx}_2^2&lt;1}. %]]&gt;&lt;/script&gt;

&lt;/blockquote&gt;

&lt;p&gt;One may easily verify that the carrier set $\cM_\kappa^n$ simplifies to the entire $\R^n$
for spherical and Euclidean geometries and to the open ball of radius 
$R=1/\sqrt{-\kappa}$ for hyperbolic geometries. Thus, another way to express
$\cM_\kappa^n$ is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\cM_\kappa^n
=
\begin{cases}
\dset{\vx\in\R^n}{\norm{\vx}_2&lt;R},
&amp; \text{for }\kappa&lt;0,
&amp; \text{hyperbolic geometry},
\\
\R^n,
&amp; \text{for }\kappa=0,
&amp; \text{Euclidean geometry},
\\
\R^n,
&amp; \text{for }\kappa&gt;0,
&amp; \text{spherical geometry}.
\end{cases} %]]&gt;&lt;/script&gt;

&lt;p&gt;For the addition in our gyrovector space algebra we use the plain-vanilla Möbius
addition:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;span class=&quot;def&quot;&gt;&lt;strong&gt;D. (Möbius Addition)&lt;/strong&gt;&lt;/span&gt; The &lt;em&gt;Möbius addition&lt;/em&gt; of $\vx,
\vy\in\cM_\kappa^n$ 
is defined as&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;\vx\oplus_\kappa\vy
=
\frac{
\left(1-2\kappa\scprod{\vx,\vy}-\kappa\norm{\vy}_2^2\right)\vx
+\left(1+\kappa\norm{\vx}_2^2\right)\vy
}{
1 - 2\kappa\scprod{\vx,\vy}+\kappa^2\norm{\vx}_2^2\norm{\vy}_2^2
}.&lt;/script&gt;
&lt;/blockquote&gt;

&lt;p&gt;An important property of the Möbius addition is that it recovers the Euclidean 
vector space addition when $\kappa\to 0$:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\lim_{\kappa\to 0}\vx \oplus_\kappa \vy = \vx + \vy.&lt;/script&gt;

&lt;p&gt;Having defined the Möbius addition, the Möbius subtraction is then simply
defined as:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;span class=&quot;def&quot;&gt;&lt;strong&gt;D. (Möbius Subtraction)&lt;/strong&gt;&lt;/span&gt; The &lt;em&gt;Möbius subtraction&lt;/em&gt; of $\vx,
\vy\in\cM_\kappa^n$ is defined as&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;\vx\ominus_\kappa\vy = \vx\oplus_\kappa(\ominus\vy).&lt;/script&gt;
&lt;/blockquote&gt;

&lt;p&gt;For $\kappa\leq 0$ it has been shown that $(\cM_\kappa^n,\oplus_\kappa)$ forms a
&lt;em&gt;commutative gyrogroup&lt;/em&gt;, where additive inverses are simply given as $\ominus \vx=-\vx$
&lt;a class=&quot;citation&quot; href=&quot;#ungar2001hyperbolic&quot;&gt;[8]&lt;/a&gt;. Furthermore, one can easily verify 
that for $\kappa=0$ the gyration becomes trivial, making the algebra $(\cM_0^n,\oplus_0)$ 
simply a &lt;em&gt;commutative group&lt;/em&gt;. However, it turns out that for $\kappa&amp;gt;0$ there are exceptions 
where the Möbius addition is indefinite:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;span class=&quot;thm&quot;&gt;&lt;strong&gt;T. (Definiteness of Möbius Addition)&lt;/strong&gt;&lt;/span&gt; The Möbius addition
is indefinite, meaning that the denominator 
$1-2\kappa\vx^\T\vy+\kappa^2\norm{\vx}_2^2\norm{\vy}_2^2=0$, 
if and only if $\kappa&amp;gt;0$ and $\vx=\vy/(\kappa\norm{\vy}_2^2)\neq 0$.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The theorem can be proven using the Cauchy-Schwarz inequality. Now, what this means 
is that for positive curvature $\kappa&amp;gt;0$, we have the situation that for every point 
$\vx$, $\vx\neq \vzero$, there exists &lt;em&gt;exactly one&lt;/em&gt; other collinear point&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\vy=\frac{1}{\kappa}\frac{\vx}{\norm{\vx}_2^2},&lt;/script&gt;

&lt;p&gt;for which the Möbius addition is indefinite. Therefore, strictly speaking, the gyrogroup 
structure is broken for $\kappa&amp;gt;0$ due to the indefiniteness of the Möbius addition in these
cases. Hence, for $\kappa&amp;gt;0$ we only get a &lt;em&gt;pseudo&lt;/em&gt; gyrogroup, which behaves like a gyrogroup,
as long as the Möbius addition is definite.&lt;/p&gt;

&lt;p&gt;However, since for every point $\vx$, $\vx\neq \vzero$, there is &lt;em&gt;only&lt;/em&gt; exactly &lt;em&gt;one&lt;/em&gt; 
other point &lt;em&gt;out of the many other possible points&lt;/em&gt; in $\cM_\kappa^n$, for which the Möbius 
addition is indefinite, this  is not too much of an issue for practical 
applications. One may circumvent these rare cases of indefinite Möbius additions by fixing 
them through min-clamping the denominator to a small numerical value $\epsilon&amp;gt;0$. This way,
the Möbius addition can be extended with desirable approximation behaviour in these indefinite 
cases.&lt;/p&gt;

&lt;p&gt;Before defining the scalar multiplication we first want to introduce the
following trigonometric functions that are parametrized by the sectional 
curvature $\kappa$. These trigonometric functions will help us to unify and
simplify the notations for spherical and hyperbolic geometry within the elegant
formalism of gyrovector spaces.&lt;/p&gt;

&lt;!-- TODO: add definition ranges of these functions at some point --&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;span class=&quot;def&quot;&gt;&lt;strong&gt;D. (Curvature-Dependent Trigonometric Functions)&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\tan_\kappa(x)
=
\begin{cases}
\frac{1}{\sqrt{-\kappa}}\tanh(\sqrt{-\kappa}x), &amp; \kappa&lt;0,\\
x, &amp; \kappa=0,\\
\frac{1}{\sqrt{\kappa}}\tan(\sqrt{\kappa}x), &amp; \kappa&gt;0.
\end{cases} %]]&gt;&lt;/script&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\arctan_\kappa(x)
=
\begin{cases}
\frac{1}{\sqrt{-\kappa}}\arctanh(\sqrt{-\kappa}x), &amp; \kappa&lt;0,\\
x, &amp; \kappa=0,\\
\frac{1}{\sqrt{\kappa}}\arctan(\sqrt{\kappa}x), &amp; \kappa&gt;0.\\
\end{cases} %]]&gt;&lt;/script&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\arcsin_\kappa(x)
=
\begin{cases}
\frac{1}{\sqrt{-\kappa}}\arcsinh(\sqrt{-\kappa}x), &amp; \kappa&lt;0,\\
x, &amp; \kappa=0,\\
\frac{1}{\sqrt{\kappa}}\arcsin(\sqrt{\kappa}x), &amp; \kappa&gt;0.\\
\end{cases} %]]&gt;&lt;/script&gt;
&lt;/blockquote&gt;

&lt;p&gt;If one ignores the definitions of the upper functions for the cases where 
$\kappa=0$, one may verify that for any 
$f_\kappa\in\set{\tan_\kappa,\arctan_\kappa,\arcsin_\kappa}$
the identity map is approached as $\kappa\to 0$:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\lim_{\kappa\to 0} f_\kappa(x)=\id(x)=x.&lt;/script&gt;

&lt;p&gt;This is exactly the motivation behind the definitions of the cases where 
$\kappa=0$. Also, these limits will become useful later when we’ll show how 
the $\kappa$-stereographic model approaches an Euclidean geometry for $\kappa\to 0$.&lt;/p&gt;

&lt;!-- TODO: put an illustrative example here at some point --&gt;

&lt;p&gt;Having defined these curvature-dependent trigonometric functions we can now
use them to define an augmented version of the Möbius scalar multiplication as 
follows:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;span class=&quot;def&quot;&gt;&lt;strong&gt;D. (Augmented Möbius Scalar Multiplication)&lt;/strong&gt;&lt;/span&gt; The 
&lt;em&gt;augmented Möbius scalar multiplication&lt;/em&gt; of $\vx\in\cM_\kappa^n\setminus\set{\vo}$ 
by $\alpha\in\R$ is defined as&lt;/p&gt;

  &lt;script type=&quot;math/tex; mode=display&quot;&gt;\alpha\otimes_\kappa \vx
=
\tan_\kappa
\left(
\alpha
\arctan_\kappa
\left(
\norm{\vx}_2
\right)\right)
\frac{\vx}{\norm{\vx}_2}.&lt;/script&gt;
&lt;/blockquote&gt;

&lt;p&gt;Hence, the augmented Möbius scalar multiplication only distinguishes itself 
from the conventional Möbius scalar multiplication through the usage of our parametrized 
trigonometric functions that also support nonnegative curvature $\kappa\geq0$.
However, there’s one subtlety for $\kappa &amp;gt; 0$ that has to be considered:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;span class=&quot;thm&quot;&gt;&lt;strong&gt;T. (Definiteness of Augmented Möbius Scalar Multiplication)&lt;/strong&gt;&lt;/span&gt; 
The augmented Möbius scalar multiplication is indefinite, if and only if
$\kappa&amp;gt;0$ and $\alpha\arctan_{\kappa}(\norm{\vx}_2)=\frac{\pi}{2}+k\pi$ 
for some $k\in\Z$.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;However, this indefiniteness is not too tragic. One may redefine the augmented
scalar multiplication for an indefinite case $\alpha\otimes_k\vx$ recursively as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\alpha\otimes_{\kappa}\vx
:=
\frac{\alpha}{2}\otimes_{\kappa}
\left(\frac{\alpha}{2}\otimes_{\kappa}\vx\right),&lt;/script&gt;

&lt;p&gt;giving an augmented gyrovector scalar multiplication that is definite for 
all real scalars.&lt;/p&gt;

&lt;p&gt;Having defined the carrier set, the gyrovector space addition and the scalar 
multiplication we now have everything for our (pseudo) gyrovector space algebra 
$(\cM_\kappa^n,\oplus_\kappa,\otimes_\kappa)$. Now, let’s have a look at how we 
can use this (pseudo) gyrovector space algebra to express all the necessary 
operations for the Poincaré ball ($\kappa&amp;lt;0$) and the stereographic projection 
of the sphere ($\kappa&amp;gt;0$):&lt;/p&gt;

&lt;table style=&quot;background-color:#f5f5f5;&quot;&gt;

&lt;tr&gt;
&lt;th style=&quot;text-align:left;&quot;&gt;Description&lt;/th&gt;
&lt;th style=&quot;text-align:center;&quot;&gt;Closed-Form Formula on $\cM_\kappa^n$, $\kappa\neq 0$&lt;/th&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Radius
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$R:=\frac{1}{\sqrt{\abs{\kappa}}}\in(0,\infty)$
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Tangent Space
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$\cT_{\vx}\cM_\kappa^n=\bbR^n$
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Conformal Factor
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$
\lambda_{\vx}^\kappa
=
\frac{2}{1+\kappa\norm{\vx}_2^2}
\in
(0,\infty)
$
&lt;/td&gt;
&lt;/tr&gt;

&lt;!--
&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Lorentz Factor
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$
\gamma_{\vx}^\kappa
=
\frac{1}{\sqrt{1+\kappa\norm{\vx}_2^2}}
\in
(0,\infty)
$
&lt;/td&gt;
&lt;/tr&gt;
--&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Metric Tensor 
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$
\vg^{\kappa}_{\vx}
=
\left(\lambda_{\vx}^\kappa\right)^2\MI
\in
\R^{n\times n}
$
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Tangent Space Inner Product 
$\scprod{\argdot,\argdot}_{\vx}^\kappa\colon\cT_{\vx}\cM_\kappa^n\times\cT_{\vx}\cM_\kappa^n\to\R$
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$
\scprod{\vu,\vv}_{\vx}^\kappa 
=
\vu^T\vg_{\vx}^\kappa\vv
=
(\lambda_{\vx}^\kappa)^2\scprod{\vu,\vv}$
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Tangent Space Norm
&lt;br /&gt;
$\norm{\argdot}_{\vx}^\kappa\colon\cT_{\vx}\cM_\kappa^n\to\R^+_0$
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$\norm{\vu}_{\vx}^\kappa=\lambda_{\vx}^\kappa\norm{\vu}_2$
&lt;/td&gt;
&lt;/tr&gt;

&lt;!-- TODO: find out what this norm is used for!!!!!!!!!!!!!!!!!!!!!!!!!!! 
&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Manifold Norm
&lt;br/&gt; 
$\norm{\argdot}_{M}^\kappa\colon\cM_\kappa^n\to\R^+_0$
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$
\norm{\vx}_{M}^\kappa
=
(\gamma_{\vx}^\kappa)^2\norm{\vx}_2
$
&lt;/td&gt;
&lt;/tr&gt;
--&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Angle $\theta_{\vx}(\vu,\vv)$ between two Tangent Vectors 
$\vu,\vv\in\cT_{\vx}\cM_\kappa^n\setminus\set{\vo}$
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$
\theta_{\vx}(\vu,\vv)
=\arccos\left(
\frac{\scprod{\vu,\vv}}{\norm{\vu}_2\norm{\vv}_2}
\right)
\quad\text{(conformal)}
$
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Distance
&lt;br /&gt; 
$d_{\kappa}\colon \cM_\kappa^n\times \cM_\kappa^n\to\R^+_0$
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$
d_{\kappa}(\vx,\vy)
=
2\arctan_\kappa\left(\norm{(-\vx)\oplus_\kappa\vy}_2\right)
$
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Distance of $\vx$ to Hyperplane $H_{\vp,\vw}$ Described by Point $\vp$ and Normal Vector $\vw$
&lt;br /&gt; 
$d_{\kappa}^{H_{\vp,\vw}}\colon \cM_\kappa^n\to\R^+_0$
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$
d_\kappa^{H_{\vp,\vw}}(\vx)
=
\arcsin_\kappa\left(
\frac{
2 \abs{\scprod{-\vp)\oplus_\kappa \vx, \vw}}
}{
\left(1+\kappa\norm{(-\vp)\oplus_\kappa \vx}_2^2\right)\norm{\vw}_2
}
\right)
$
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Exponential Map
&lt;br /&gt;
$\exp_{\vx}^{\kappa}\colon\cT_{\vx}\cM_\kappa^n\to\cM_\kappa^n$
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$
\exp_{\vx}^{\kappa}(\vu)
=
\vx\oplus_\kappa
\left(
\tan_\kappa\left(
\frac{1}{2}
\norm{\vu}_{\vx}^\kappa
\right)
\frac{\vu}{\norm{\vu}_2}
\right)
$
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Log Map
&lt;br /&gt;
$\log_{\vx}^\kappa\colon\cM_\kappa^n\to\cT_{\vx}\cM_\kappa^n$
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$
\log_{\vx}^\kappa(\vy)=
2\arctan_\kappa\left(\norm{(-\vx)\oplus_\kappa\vy}_2\right)
\frac{(-\vx)\oplus_\kappa \vy}{\norm{(-\vx)\oplus_\kappa \vy}_{\vx}^\kappa}
$
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Geodesic from $\vx\in\cM_\kappa^n \text{ to } \vy\in\cM_\kappa^n$
&lt;br /&gt;
$\vgamma_{\vx\to\vy}^\kappa\colon [0,1]\to\cM_\kappa^n$
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$
\vgamma_{\vx\to\vy}^{\kappa}(t)=\vx\oplus_\kappa\left(t\otimes_\kappa\left((-\vx)
\oplus_\kappa\vy\right)
\right)
$
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Unit-Speed Geodesic at Time $t\in\R$
Starting from $\vx\in\cM_\kappa^n$ in Direction of $\vu\in\cT_{\vx}\cM_\kappa^n$
&lt;br /&gt;
$\vgamma_{\vx,\vu}^{\kappa}\colon \R\to\cM_\kappa^n$
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$
\vgamma_{\vx,\vu}^{\kappa}(t)
=
\vx \oplus_\kappa
\left(
\tan_\kappa\left(
\frac{1}{2}t
\right)
\frac{\vu}{\norm{\vu}_2}
\right)
$
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Antipode $\vx^a$ of $\vx$ for $\kappa&amp;gt;0$
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$
\vx^a
=
\frac{1}{\lambda_{\vx}^{\kappa}\kappa\norm{\vx}_2^2}(-\vx)
$
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Weighted Midpoint
&lt;br /&gt;
$\vm_{\kappa}\colon (\cM_\kappa^d)^n\times\R^n\to\cM_\kappa^d$
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$
\vm_\kappa(\vx_{1:n},\alpha_{1:n})
=
\frac{1}{2}
\otimes_\kappa
\left(
\sum_{i=1}^n
\frac{
\alpha_i\lambda_{\vx_i}^\kappa
}{
\sum_{j=1}^n\alpha_j(\lambda_{\vx_i}^\kappa - 1)
}
\vx_i
\right)
$
&lt;br /&gt;
for $\kappa&amp;gt;0$ this also requires determining which of
$\vm_{\kappa}$ and $\vm_{\kappa}^a$ minimizes the sum of distances
&lt;br /&gt;
&lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;

&lt;p&gt;The formulas in the table above clearly illustrate how dual the Poincaré ball 
and the stereographic projection of the sphere are. In hindsight, the duality of 
the two stereographic models is not so surpising, since both models are 
the stereographic projections of the hyperboloid and the sphere, which are known 
to be dual. Now, let’s see next how the dual models connect even more for 
$\kappa\to 0$.&lt;/p&gt;

&lt;h2 id=&quot;recovery-of-euclidean-geometry-as-kappato-0&quot;&gt;Recovery of Euclidean Geometry as $\kappa\to 0$&lt;/h2&gt;

&lt;p&gt;The following formulas show how in the limit $\kappa\to\ 0$ an Euclidean geometry,
with a Cartesian coordinate system at intervals of $2$ units, is recovered:&lt;/p&gt;

&lt;table style=&quot;background-color:#f5f5f5;&quot;&gt;

&lt;tr&gt;
&lt;th style=&quot;text-align:left;&quot;&gt;Description&lt;/th&gt;
&lt;th style=&quot;text-align:center;&quot;&gt;Closed-Form Formula on $\cM_\kappa^n$ for $\kappa\to 0$&lt;/th&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Radius
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$R\to\infty$
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Tangent Space
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$\cT_{\vx}\cM_0^n=\bbR^n$
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Conformal Factor
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$
\lambda_{\vx}^0
=
2
$
&lt;/td&gt;
&lt;/tr&gt;

&lt;!--
&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Lorentz Factor
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$
\gamma_{\vx}^0
=
1
$
&lt;/td&gt;
&lt;/tr&gt;
--&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Metric Tensor 
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$
\vg^{0}_{\vx}
=
(\lambda_{\vx}^0)^2\MI
=
4\MI
\in
\R^{n\times n}
$
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Tangent Space Inner Product 
$\scprod{\argdot,\argdot}_{\vx}^0\colon\cT_{\vx}\cM_0^n\times\cT_{\vx}\cM_0^n\to\R$
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$
\scprod{\vu,\vv}_{\vx}^0 
=
\vu^T\vg_{\vx}^0\vv
=
(\lambda_{\vx}^0)^2\scprod{\vu,\vv}
=
4\scprod{\vu,\vv}
$
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Tangent Space Norm
&lt;br /&gt;
$\norm{\argdot}_{\vx}^0\colon\cT_{\vx}\cM_0^n\to\R^+_0$
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$\norm{\vu}_{\vx}^0=\lambda_{\vx}^0\norm{\vu}_2=2\norm{\vu}_2$
&lt;/td&gt;
&lt;/tr&gt;

&lt;!-- TODO: find out what this norm is used for!!!!!!!!!!!!!!!!!!!!!!!!!!!
&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Manifold Norm
&lt;br/&gt; 
$\norm{\argdot}_{M}^0\colon\cM_0^n\to\R^+_0$
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$
\norm{\vx}_{M}^0
=
(\gamma_{\vx}^0)^2\norm{\vx}_2
=
\norm{\vx}_2
$
&lt;/td&gt;
&lt;/tr&gt;
--&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Angle $\theta_{\vx}(\vu,\vv)$ between two Tangent Vectors 
$\vu,\vv\in\cT_{\vx}\cM_0^n\setminus\set{\vo}$
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$
\theta_{\vx}(\vu,\vv)
=\arccos\left(
\frac{\scprod{\vu,\vv}}{\norm{\vu}_2\norm{\vv}_2}
\right)
$
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Distance
&lt;br /&gt; 
$d_{0}\colon \cM_0^n\times \cM_0^n\to\R^+_0$
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$
d_{0}(\vx,\vy)
=
2\norm{\vx-\vy}_2
$
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Distance of $\vx$ to Hyperplane $H_{\vp,\vw}$ Described by Point $\vp$ and Normal Vector $\vw$
&lt;br /&gt; 
$d_{\kappa}^{H_{\vp,\vw}}\colon \cM_\kappa^n\to\R^+_0$
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$
d_\kappa^{H_{\vp,\vw}}(\vx)
=
2 \abs{\scprod{\vx-\vp, \frac{\vw}{\norm{\vw}_2} }}
$
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Exponential Map
&lt;br /&gt;
$\exp_{\vx}^{0}\colon\cT_{\vx}\cM_0^n\to\cM_0^n$
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$
\exp_{\vx}^{0}(\vu)
=
\vx+\vu
$
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Log Map
&lt;br /&gt;
$\log_{\vx}^0\colon\cM_0^n\to\cT_{\vx}\cM_0^n$
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$
\log_{\vx}^0(\vy)=
\vy-\vx
$
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Geodesic from $\vx\in\cM_0^n \text{ to } \vy\in\cM_0^n$
&lt;br /&gt;
$\vgamma_{\vx\to\vy}^0\colon [0,1]\to\cM_0^n$
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$
\vgamma_{\vx\to\vy}^{0}(t)
=
\vx+t(\vy-\vx)
$
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Unit-Speed Geodesic at Time $t\in\R$
Starting from $\vx\in\cM_0^n$ in Direction of $\vu\in\cT_{\vx}\cM_0^n$
&lt;br /&gt;
$\vgamma_{\vx,\vu}^{0}\colon \R\to\cM_0^n$
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$
\vgamma_{\vx,\vu}^{0}(t)
=
\vx +
\frac{1}{2}t
\frac{\vu}{\norm{\vu}_2}
$
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td style=&quot;text-align:left;&quot;&gt;
Weighted Midpoint
&lt;br /&gt;
$\vm_{0}\colon (\cM_\kappa^d)^n\times\R^n\to\cM_\kappa^d$
&lt;/td&gt;
&lt;td style=&quot;vertical-align:middle; padding-left:0px; padding-right:10px;&quot;&gt;
$
\vm_\kappa(\vx_{1:n},\alpha_{1:n})
=
\sum_{i=1}^n
\frac{
\alpha_i
}{
\sum_{j=1}^n\alpha_j
}
\vx_i
$
&lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;

&lt;!-- 
TODO: log-map, behaviour (not unique for positive curvature). 
That's maybe what makes the matrix multiplication tests fail
for positive curvature.
--&gt;

&lt;p&gt;The formulas for the Euclidean geometry have a “2” or a “4” here and there
which comes from the fact that the points $\vx,\vy$ are in the basis of a 
Cartesian coordinate system with intervals of size 2. This coordinate system just
emerges in the limit $\kappa\to 0$ from the Poincaré ball and also from the 
stereographic projection of the sphere, which both can be seen as a coordinate 
systems for a corresponding hyperbolic and spherical geometry, respectively.&lt;/p&gt;

&lt;p&gt;A few things to note in the formulas of above are: that the exponential- and the 
logmap are simply given through vector addition and subtraction. Also, the
distance is simply upscaled by a factor of 2 due to the choice of coordinates. The 
weighted midpoint simply becomes the familiar weighted average.&lt;/p&gt;

&lt;h2 id=&quot;grids-of-geodesics-at-equidistant-intervals&quot;&gt;Grids of Geodesics at Equidistant Intervals&lt;/h2&gt;

&lt;p&gt;Now that we’ve entirely described the models mathematically, let’s also
build up our intuitions through some illustrations of the geometries in 2D.
First, we want to see how a grid of equidistant geodesics in two orthogonal
directions looks like in the geometries of constant curvature.&lt;/p&gt;

&lt;h3 id=&quot;grid-of-geodesics-on-euclidean-manifold&quot;&gt;Grid of Geodesics on Euclidean Manifold&lt;/h3&gt;

&lt;p&gt;Here’s how a grid of geodesics looks like on the $x/y$-plane,
a.k.a. the 2D Euclidean manifold. Actually, that’s nothing special, the grid
just consists of straight lines, reminding us of the Cartesian coordinate 
system. Note that this 2D grid could be a cross-section of a 3D Euclidean 
geometry.&lt;/p&gt;

&lt;div class=&quot;figure-with-caption&quot;&gt;
&lt;div class=&quot;figure-title&quot;&gt;
Grid of Geodesics at Equidistant Intervals&lt;br /&gt; on Euclidean Manifold&lt;br /&gt; ($\kappa=0$)
&lt;/div&gt;
&lt;img src=&quot;/img/2019-11-21-K-Stereographic-Model/grid-of-geodesics-K-0.0.svg?v=4&quot; alt=&quot;Grid of Geodesics at Equidistant Intervals on Euclidean Manifold&quot; width=&quot;100%&quot; /&gt;
&lt;/div&gt;

&lt;h3 id=&quot;grid-of-geodesics-on-poincaré-ball&quot;&gt;Grid of Geodesics on Poincaré Ball&lt;/h3&gt;

&lt;p&gt;Now, let’s get a feeling of how a grid of geodesics at equidistant 
intervals on the $x/y$-axes looks like on the Poincaré disk:&lt;/p&gt;

&lt;div class=&quot;figure-with-caption&quot;&gt;
&lt;div class=&quot;figure-title&quot;&gt;
Grid of Geodesics at Equidistant Intervals&lt;br /&gt; on Poincaré Ball&lt;br /&gt; ($\kappa=-1$)
&lt;/div&gt;
&lt;img src=&quot;/img/2019-11-21-K-Stereographic-Model/grid-of-geodesics-K--1.0.svg?v=3&quot; alt=&quot;Grid of Geodesics at Equidistant Intervals on Poincaré Ball&quot; width=&quot;100%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Recall, that the points on the Poincaré disk result from the stereographic
projection of the hyperboloid. Here are a few things to note about the grid 
of geodesics on the Poincaré ball.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The center of the Poincaré ball, which we also refer to as the origin, represents
the lower tip of the upper sheet of the two-sheeted hyperboloid.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The border of the Poincaré ball represents points at infinity, or alternatively,
points on the hyperboloid that are infinitely far away from the origin.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The geodesics intersect the border of the Poincaré ball at a right angle.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;From a plain “eye” point-of-view the interval between the geodesics becomes
tighter and tighter towards the border of the Poincaré ball. But according
to the hyperbolic metric they are equidistant. This tightening happens because 
volumes and distances towards border of the Poincaré ball grow exponentially,
since close to the border, even small dislocations on the Poincaré ball
correspond to large dislocations on the hyperboloid.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;One can also imagine how a 3D hyperbolic geometry looks like if one imagines that
this 2D grid of geodesics is the cross-section of the inside of a 3D Poincaré ball.&lt;/p&gt;

&lt;h3 id=&quot;grid-of-geodesics-on-stereographic-projection-of-sphere&quot;&gt;Grid of Geodesics on Stereographic Projection of Sphere&lt;/h3&gt;

&lt;p&gt;Here’s how the equivalent grid of geodesics looks like for the stereographic
projection of the 2D sphere:&lt;/p&gt;

&lt;div class=&quot;figure-with-caption&quot;&gt;
&lt;div class=&quot;figure-title&quot;&gt;
Grid of Geodesics at Equidistant Intervals&lt;br /&gt; on Stereographic Projection of Sphere
&lt;br /&gt; 
($\kappa=1$)
&lt;/div&gt;
&lt;img src=&quot;/img/2019-11-21-K-Stereographic-Model/grid-of-geodesics-K-1.0.svg?v=2&quot; alt=&quot;Grid of Geodesics at Equidistant Intervals on Stereographic Projection of Sphere&quot; width=&quot;100%&quot; /&gt;
&lt;div class=&quot;figure-caption&quot; style=&quot;text-align:center&quot;&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Some things to note in this grid are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The center inside the ball is the stereographic projection of the south pole.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The ball marked in bold corresponds to the equator of the 2D sphere.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;All the geodesics actually represent a great-circle of the 2D sphere.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The geodesic length of the part of a great-circle that is inside the bold ball
(equator) is equal to the geodesic length of the part of the great-circle that is
on the outside of the equator.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Each pair of geodesics meets exactly twice.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Similarly, one can also imagine how a 3D spherical geometry would look like if one
thinks of this grid as a cross-section of a 3D spherical geometry.&lt;/p&gt;

&lt;h2 id=&quot;illustrations-of-smooth-interpolations-between-geometries-of-positive-and-negative-curvature&quot;&gt;Illustrations of Smooth Interpolations between Geometries of Positive and Negative Curvature&lt;/h2&gt;

&lt;p&gt;In the following we want to illustrate how the $\kappa$-stereographic model
allows to compute useful notions for the manifolds of constant curvature
and how these notions smoothly interpolate for changes of the curvature 
$\kappa$.&lt;/p&gt;

&lt;h3 id=&quot;parallel-transport-of-unit-gyrovectors&quot;&gt;Parallel Transport of Unit Gyrovectors&lt;/h3&gt;

&lt;p&gt;The following animation shows how the parallel transport of unit gyrovectors
smoothly adapts to changing values of the curvature $\kappa$:&lt;/p&gt;

&lt;div class=&quot;figure-with-caption&quot;&gt;
&lt;div class=&quot;figure-title&quot;&gt;
Parallel Transport of Gyrovectors
&lt;/div&gt;
&lt;img src=&quot;/img/2019-11-21-K-Stereographic-Model/gyrovector-parallel-transport.gif?v=2&quot; alt=&quot;Parallel Transport of Gyrovectors&quot; width=&quot;100%&quot; /&gt;
&lt;/div&gt;

&lt;h3 id=&quot;midpoints&quot;&gt;Midpoints&lt;/h3&gt;

&lt;p&gt;The following animation shows how the equally-weighted geodesic midpoint 
$\vm_{\kappa}$ of $\vx_1,\ldots,\vx_4$ smoothly changes for changes 
in $\kappa$. The corresponding shortest paths from the points $\vx_1,\ldots,\vx_4$ to their 
midpoint $\vm_{\kappa}$ are also illustrated. For positive curvature the antipode of 
the midpoint $\vm_{\kappa}$ is also shown.&lt;/p&gt;

&lt;div class=&quot;figure-with-caption&quot;&gt;
&lt;div class=&quot;figure-title&quot;&gt;
Midpoint
&lt;/div&gt;
&lt;img src=&quot;/img/2019-11-21-K-Stereographic-Model/midpoint.gif?v=4&quot; alt=&quot;Midpoint&quot; width=&quot;100%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;Observe how for positive curvature the midpoint moves to the northern hemisphere once that the
embeddings of $\vx_1,\ldots,\vx_4$ also start to reside there.&lt;/p&gt;

&lt;h3 id=&quot;geodesic-distance&quot;&gt;Geodesic Distance&lt;/h3&gt;

&lt;p&gt;The following animation shows how the scalar field of distances to a 
point $\vx$ smoothly transforms for various curvatures. One thing
to note here is how for spherical geometries with a large curvature
the maximal representable distance becomes very small due to the
spherical structure of the manifold. Another thing to notice for 
negative curvature is that most of the space resides at the border
of the Poincaré ball - thus it is crucial to work with &lt;code class=&quot;highlighter-rouge&quot;&gt;float64&lt;/code&gt; in
order to represent distances accurately.&lt;/p&gt;

&lt;div class=&quot;figure-with-caption&quot;&gt;
&lt;div class=&quot;figure-title&quot;&gt;
Geodesic Distance
&lt;/div&gt;
&lt;img src=&quot;/img/2019-11-21-K-Stereographic-Model/distance.gif?v=3&quot; alt=&quot;Distance&quot; width=&quot;100%&quot; /&gt;
&lt;div class=&quot;figure-caption&quot; style=&quot;text-align:center&quot;&gt;
Heatmap of square root of distance $\sqrt{d_{\kappa}(\vx,\argdot)}$ to $\vx$
&lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;hyperplane-distance&quot;&gt;Hyperplane Distance&lt;/h3&gt;

&lt;p&gt;The following animation shows how the scalar field of distances to a 
hyperplane smoothly transforms for various curvatures. The hyperplane
is described by a a point $\vp$ on the hyperplane and a normal vector $\vw$.
Note how the hyperplane just becomes a straight line for $\kappa\to 0$
and a great-cricle for $\kappa&amp;gt;0$:&lt;/p&gt;

&lt;div class=&quot;figure-with-caption&quot;&gt;
&lt;div class=&quot;figure-title&quot;&gt;
Hyperplane Distance
&lt;/div&gt;
&lt;img src=&quot;/img/2019-11-21-K-Stereographic-Model/distance2plane.gif?v=3&quot; alt=&quot;Distance to Hyperplane&quot; width=&quot;100%&quot; /&gt;
&lt;div class=&quot;figure-caption&quot; style=&quot;text-align:center&quot;&gt;
Heatmap of square root of hyperplane distance $\sqrt{d_{\kappa}^{H_{\vp,\vw}}(\argdot)}$
&lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;implementation-of-kappa-stereographic-model&quot;&gt;Implementation of $\kappa$-Stereographic Model&lt;/h2&gt;

&lt;p&gt;An Pytorch implementation of the $\kappa$-stereographic model was contributed by
Andreas Bloch to the open-source geometric optimization library geoopt. The code for
the $\kappa$-stereographic model can be found here:&lt;/p&gt;

&lt;p style=&quot;text-align:center&quot;&gt;
&lt;a class=&quot;btn btn-default btn-sm&quot; href=&quot;https://github.com/andbloch/geoopt/tree/universal-manifold/geoopt/manifolds/stereographic&quot; target=&quot;_blank&quot;&gt;
&lt;i class=&quot;fa fa-github fa-2&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; Source of $\kappa$-Stereographic Model&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;Note that the implementation doesn’t support the Euclidean geometry for $\kappa=0$. 
Instead only the cases $\abs{\kappa}&amp;gt;0.001$ are supported, such that the formulas of
above always provide gradients for $\kappa$ in order to be able to learn the curvatures
of embedding spaces.&lt;/p&gt;

&lt;h2 id=&quot;code-example-for-kappa-stereographic-model&quot;&gt;Code Example for $\kappa$-Stereographic Model&lt;/h2&gt;

&lt;p&gt;Here’s a quick code example that shows how the $\kappa$-stereographic model can be instantiated 
and used to perform some of the aforementioned operations. The code example also shows
how to train the curvature $\kappa$ to achieve certain targets.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;geoopt.manifolds.stereographic&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StereographicExact&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;geoopt.optim&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RiemannianAdam&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;geoopt&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ManifoldTensor&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;geoopt&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ManifoldParameter&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# MANIFOLD INSTANTIATION AND COMPUTATION OF MANIFOLD QUANTITIES ################
&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# create manifold with initial K=-1.0 (Poincaré Ball)
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;manifold&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StereographicExact&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                              &lt;span class=&quot;n&quot;&gt;float_precision&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                              &lt;span class=&quot;n&quot;&gt;keep_sign_fixed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                              &lt;span class=&quot;n&quot;&gt;min_abs_K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# get manifold properties
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;manifold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;R&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;manifold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_R&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;K={K}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;R={R}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# define dimensionality of space
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create_random_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manifold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;manifold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_R&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# create two random points on manifold
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_random_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manifold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create_random_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manifold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# compute their initial distances
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;initial_dist&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;manifold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;initial_dist={initial_dist.item():.3f}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# compute the log map of y at x
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;manifold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logmap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# compute tangent space norm of v at x (should be equal to initial distance)
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;v_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;manifold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;v_norm={v_norm.item():.3f}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# compute the exponential map of v at x (=y)
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;manifold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expmap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;diff&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;diff={diff.item():.3f}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# CURVATURE OPTIMIZATION #######################################################
&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# define embedding_optimizer for curvature
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;curvature_optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manifold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_trainable_K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# set curvature to trainable
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;manifold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_K_trainable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# define training loop to optimize curvature until the points have a
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# certain target distance
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train_curvature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_dist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;curvature_optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dist_now&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;manifold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dist_now&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_dist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;curvature_optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# keep the points x and y fixed,
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# train the curvature until the distance is 0.1 more than the initial distance
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# --&amp;gt; curvature smaller than initial curvature
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_curvature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;initial_dist&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;K_smaller={manifold.get_K().item():.3f}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# keep the points x and y fixed,
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# train the curvature until the distance is 0.1 less than the initial distance
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# --&amp;gt; curvature greater than initial curvature
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_curvature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;initial_dist&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;K_larger={manifold.get_K().item():.3f}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# EMBEDDING OPTIMIZATION #######################################################
&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# redefine x and y as manifold parameters and assign them to manifold such
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# that the embedding_optimizer knows according to which manifold the gradient
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# steps have to be performed
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ManifoldTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;manifold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manifold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ManifoldParameter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ManifoldTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;manifold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;manifold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ManifoldParameter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# define embedding optimizer and pass embedding parameters
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;embedding_optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RiemannianAdam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# define a training loop to optimize the embeddings of x and y
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# until they have a certain distance
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train_embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_dist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;embedding_optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dist_now&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;manifold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dist_now&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_dist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;embedding_optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# print current distance
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;dist(x,y)={manifold.dist(x,y).item():.3f}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# optimize until points have target distance of 4.0
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;4.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;dist(x,y)={manifold.dist(x,y).item():.3f}  target:4.0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# optimize until points have target distance of 2.0
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;dist(x,y)={manifold.dist(x,y).item():.3f}  target:2.0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;That’s all for the $\kappa$-stereographic model. We hope that this blogpost
and the provided implementation supports the sparking of new ideas for 
applications of our $\kappa$-stereographic model.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;span id=&quot;gu2018learning&quot;&gt;A. Gu, F. Sala, B. Gunel, and C. Ré, “Learning Mixed-Curvature Representations in Product Spaces,” 2018.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;skopek2019mixed&quot;&gt;O. Skopek, O.-E. Ganea, and G. Bécigneul, “Mixed-curvature Variational Autoencoders,” &lt;i&gt;arXiv preprint arXiv:1911.08411&lt;/i&gt;, 2019.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;bachmann2019constant&quot;&gt;G. Bachmann, G. Bécigneul, and O.-E. Ganea, “Constant Curvature Graph Convolutional Networks,” &lt;i&gt;arXiv preprint arXiv:1911.05076&lt;/i&gt;, 2019.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;wilson2014spherical&quot;&gt;R. C. Wilson, E. R. Hancock, E. Pekalska, and R. P. W. Duin, “Spherical and hyperbolic embeddings of data,” &lt;i&gt;IEEE transactions on pattern analysis and machine intelligence&lt;/i&gt;, vol. 36, no. 11, pp. 2255–2269, 2014.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;ungar2005analytic&quot;&gt;A. A. Ungar, &lt;i&gt;Analytic hyperbolic geometry: Mathematical foundations and applications&lt;/i&gt;. World Scientific, 2005.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;ungar1991thomas&quot;&gt;A. A. Ungar, “Thomas precession and its associated grouplike structure,” &lt;i&gt;American Journal of Physics&lt;/i&gt;, vol. 59, no. 9, pp. 824–834, 1991.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;hnn&quot;&gt;O. Ganea, G. Bécigneul, and T. Hofmann, “Hyperbolic neural networks,” in &lt;i&gt;Advances in neural information processing systems&lt;/i&gt;, 2018, pp. 5345–5355.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;ungar2001hyperbolic&quot;&gt;A. A. Ungar, “Hyperbolic trigonometry and its application in the Poincaré ball model of hyperbolic geometry,” &lt;i&gt;Computers &amp;amp; Mathematics with Applications&lt;/i&gt;, vol. 41, no. 1-2, pp. 135–147, 2001.&lt;/span&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>Andreas Bloch in collaboration with Ondrej Skopek and Gregor Bachmann under the assistance of Octavian Ganea and Gary Bécigneul</name></author><category term="math" /><category term="geometry" /><category term="riemannian manifolds" /><summary type="html">This blogpost presents a geometric model that harnesses the formalism gyrovector spaces in order to capture all three geometries of constant curvature at once. Furthermore, the presented model allows to smoothly interpolate between the geometries of constant curvature in order to learn the curvature of spaces jointly with the embeddings.</summary></entry><entry><title type="html">Stochastic Gradient Descent on Riemannian Manifolds</title><link href="http://localhost:4000/Stochastic-Gradient-Descent-on-Riemannian-Manifolds/" rel="alternate" type="text/html" title="Stochastic Gradient Descent on Riemannian Manifolds" /><published>2019-10-15T16:00:00+02:00</published><updated>2019-10-15T16:00:00+02:00</updated><id>http://localhost:4000/Stochastic-Gradient-Descent-on-Riemannian-Manifolds</id><content type="html" xml:base="http://localhost:4000/Stochastic-Gradient-Descent-on-Riemannian-Manifolds/">&lt;p&gt;In this blogpost I’ll explain how Stochastic Gradient Descent (SGD) is generalized to the 
optimization of loss functions on Riemannian manifolds. 
First, I’ll give an overview of the kind of problems that are suited for Riemannian 
optimization. Then, I’ll explain how &lt;em&gt;Riemannian Stochastic Gradient Descent (RSGD)&lt;/em&gt; works 
in detail and I’ll also show how RSGD is performed in the case where the Riemannian manifold of 
interest is a product space of several Riemannian manifolds. If you’re already experienced 
with SGD and you’re just about getting started with Riemannian optimization this blogpost is 
exactly what you were looking for.&lt;/p&gt;

&lt;h2 id=&quot;typical-riemannian-optimization-problems&quot;&gt;Typical Riemannian Optimization Problems&lt;/h2&gt;

&lt;p&gt;Let’s first consider the properties of optimization problems that we’d
typically want to solve through Riemannian optimization. Riemannian optimization 
is particularly well-suited for problems where we want to optimize a loss function&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\cL\colon\cM&amp;\to\R
\\
\vtheta&amp;\mapsto\cL(\vtheta)
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;that is defined on a &lt;em&gt;Riemannian manifold&lt;/em&gt; $(\cM,g)$. This means that
the optimization problem &lt;em&gt;requires&lt;/em&gt; that the optimized parameters $\vtheta\in\cM$ 
lie on the “smooth surface” of a Riemannian manifold $(\cM,g)$. One can easily
think of constrained optimization problems where the constraint can be described through
points lying on a Riemannian manifold (e.g., the parameters must lie on a sphere, the parameters
must be a rotation matrix, …). Riemannian optimization then gives us the possibilty
of turning a constrained optimization problem into an unconstrained one that 
can be naturally solved via Riemannian optimization.&lt;/p&gt;

&lt;p&gt;So, in Riemannian optimization we’re interested in finding an optimal solution $\vtheta^*$ for our 
parameters&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\vtheta^*\in\argmin_{\vtheta} \cL(\vtheta)&lt;/script&gt;

&lt;p&gt;that lie on a Riemannian manifold. The following two figures illustrate the heatmaps 
of some non-convex loss functions, that are defined on an Euclidean and spherical 
Riemannian manifold.&lt;/p&gt;

&lt;div class=&quot;figure-with-caption&quot;&gt;
&lt;img src=&quot;/img/2019-10-15-Stochastic-Gradient-Descent-on-Riemannian-Manifolds/heatmap-plane.png?v=1&quot; alt=&quot;Heatmap of loss function defined on the Euclidean plane&quot; width=&quot;70%&quot; /&gt;
&lt;div class=&quot;figure-caption&quot; style=&quot;text-align:center&quot;&gt;
Heatmap of a loss function $\cL$ defined on the Euclidean plane
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;figure-with-caption&quot;&gt;
&lt;img src=&quot;/img/2019-10-15-Stochastic-Gradient-Descent-on-Riemannian-Manifolds/heatmap-sphere.png?v=1&quot; alt=&quot;Heatmap of loss function a spherical manifold&quot; width=&quot;40%&quot; /&gt;
&lt;div class=&quot;figure-caption&quot; style=&quot;text-align:center&quot;&gt;
Heatmap of a loss function $\cL$ defined on a spherical manifold
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Similarly as with SGD in Euclidean vector spaces, in Riemannian optimization we want
to perform a gradient-based descent on the surface of the manifold. The gradient steps should 
also be based on the gradients of the loss fuction $\cL$, such that we finally find some
parameters $\vtheta^*$ that hopefully lie at a global minimum of the loss.&lt;/p&gt;

&lt;h2 id=&quot;whats-different-with-sgd-on-riemannian-manifolds&quot;&gt;What’s Different with SGD on Riemannian Manifolds&lt;/h2&gt;

&lt;p&gt;Let’s first look at what makes RSGD different from the usual SGD in the 
Euclidean vector spaces. Actually, RSGD just works like SGD when applied to our well-known
Euclidean vector spaces, because RSGD is just a generalization of SGD to arbitrary 
Riemannian manifolds.&lt;/p&gt;

&lt;p&gt;Indeed, the Euclidean vector space $\R^n$ can be interpreted as a Riemannian 
manifold $(\R^n, g_{ij})$, known as the &lt;em&gt;Euclidean manifold&lt;/em&gt;, with the 
metric $g_{ij}=\delta_{ij}$. When using our usual SGD to optimize a loss function defined over 
the Euclidean manifold $\R^n$, we iteratively compute the following gradients and 
gradient updates on minibatches in order to hopefully converge to an optimal solution:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\nabla_{\vtheta}\cL(\vtheta)&amp;=\left(\fpartial{\cL(\theta)}{\theta_i}\right)_{i=1}^d,
\\
\vtheta^{(t+1)}&amp;\gets\vtheta^{(t)}-\eta_t\nabla_{\vtheta}\cL(\vtheta^{(t)}).
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;Now, in some optimization problems the solution space, or solution manifold $\cM$, 
might have a structure that is different from the Euclidean manifold. Let’s consider 
two examples of optimization problems that can be captured as Riemannian optimization
problems and let’s have a look at the challenges that arise in the gradient updates:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Points on a Sphere:&lt;/strong&gt; The optimization problem may require that the 
parameters $\vtheta=(x,y,z)$ lie on a 2D-spherical manifold of radius 1 that 
is embedded in 3D ambient space. The corresponding Riemannian manifold $(\cM,g)$ would 
then be&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\cM&amp;=\sdset{\vtheta\in\R^{3}}{\norm{\vtheta}_2=1},
\\
g&amp;=\MI.
\end{align*} %]]&gt;&lt;/script&gt;

    &lt;p&gt;In this case we have a loss function $\cL\colon\cM\to\R$ that gives 
us the loss for any point (or parameter) $\vtheta$ on the sphere $\cM$. 
Our machine learning framework might then automatically provide us with the 
derivatives of the loss&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\vh(\vtheta^{(t)})
=
\left(
\fpartial{\cL(\vtheta^{(t)})}{x},
\fpartial{\cL(\vtheta^{(t)})}{y},
\fpartial{\cL(\vtheta^{(t)})}{z}
\right)&lt;/script&gt;

    &lt;p&gt;evaluated at our current parameters $\vtheta^{(t)}$. But now, how are we going about 
updating the parameters $\vtheta^{(t)}$ with $\vh(\vtheta^{(t)})$? We can’t 
just use our well-known update-rule of SGD for Euclidean vector spaces, since 
we’re not guaranteed that the update rule&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\vtheta^{(t+1)}\gets\vtheta^{(t)}-\eta_t\vh(\vtheta^{(t)})&lt;/script&gt;

    &lt;p&gt;yields a valid update $\vtheta^{(t+1)}$ that lies on the surface of spherical 
manifold $\cM$. Before seeing how this can be solved through Riemannian optimization,
let’s first consider another example where we encounter a similar issue.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Doubly-Stochastic Matrices:&lt;/strong&gt; One may also think of a more complicated
optimization problem, where the parameters $\vtheta$ must be a square matrix with positive 
coefficients such that the coefficients of every row and column sum up to 1.
It turns out that this solution space $\cM$ also represents a Riemannian manifold,
having thus a smooth “surface” and a metric $g_{\MX}$ that smoothly varies with $\MX$.
This Riemannian manifold $(\cM,g_{\MX})$ is the manifold of so-called &lt;em&gt;doubly-stochastic 
matrices&lt;/em&gt; &lt;a class=&quot;citation&quot; href=&quot;#douik2018manifold&quot;&gt;[1]&lt;/a&gt;, given by:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\cM&amp;=\dset{\MX\in\R^{d\times d}}{
\begin{array}{rl}
\forall i,j\in\set{1,\ldots,d}\colon 
&amp;X_{ij}\geq 0,
\\
\forall i\in\set{1,\ldots,d}\colon 
&amp;\sum_{k=1}^d X_{ik}=\sum_{k=1}^d X_{ki} = 1.
\end{array}
},
\\
g_{\MX}&amp;=\Tr{(\MA\oslash\MX)\MB^\T}.
\end{align*} %]]&gt;&lt;/script&gt;

    &lt;p&gt;Again, our machine learning framework may give us the derivatives of the 
loss w.r.t. each of the parameter matrix’ coefficients and evaluate it at our 
current parameters $\vtheta^{(t)}$:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\MH(\vtheta^{(t)})
=
\left(
\fpartial{\cL(\vtheta)}{X_{ij}}
\right)_{i,j=1}^{d}.&lt;/script&gt;

    &lt;p&gt;Again, the simple gradient-update rule of SGD for parameters in Euclidean 
vector spaces&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\vtheta^{(t+1)}\gets\vtheta^{(t)}-\eta_t\MH(\vtheta^{(t)})&lt;/script&gt;

    &lt;p&gt;would not guarantee us that the update always yields a matrix $\vtheta^{(t+1)}$ with 
nonnegative coefficients whose rows and columns sum up to 1.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In both examples we saw that the simple SGD update-rule for Euclidean vector spaces is 
insufficient to guarantee the validity of the updated parameters. So now the question is, 
how can we perform valid gradient updates to parameters that are defined on arbitrary 
Riemannian manifolds? – That’s exactly where Riemannian optimization comes in, which we’ll
look at next!&lt;/p&gt;

&lt;h2 id=&quot;performing-gradient-steps-on-riemannian-manifolds&quot;&gt;Performing Gradient Steps on Riemannian Manifolds&lt;/h2&gt;

&lt;p&gt;In the “curved” spaces of Riemannian manifolds the gradient updates 
ideally should follow the “curved” geodesics instead of just following straight 
lines as done in SGD for parameters on our familiar Euclidean manifold $\bbR^n$. 
To this end, the seminal work of Bonnabel &lt;a class=&quot;citation&quot; href=&quot;#bonnabel&quot;&gt;[2]&lt;/a&gt; introduced 
&lt;em&gt;Riemannian Stochastic Gradient Descent (RSGD)&lt;/em&gt; that generalizes SGD to Riemannian manifolds.
In what follows I’ll explain and illustrate how this technique works.&lt;/p&gt;

&lt;p&gt;Let’s now assume that we have a typical Riemannian optimization problem, e.g., one of the
two mentioned previously, where the solution space is given by an arbitrary 
$d$-dimensional Riemannian manifold $(\cM, g)$ and we’re interested in finding an optimal solution 
of a loss function $\cL\colon\cM\to\cR$, that is defined for any parameters $\vtheta$ on the 
Riemannian manifold. Let $\vtheta^{(t)}\in\cM$ denote our current set of parameters at
timestep $t$. A gradient-step is then performed through the application of the following three 
steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Evaluate the gradient of $\cL$ w.r.t. the parameters $\vtheta$ at $\vtheta^{(t)}$.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Orthogonally project the gradient onto the tangent space $\cT_{\vtheta^{(t)}}\cM$ to get
the tangent vector $\vv$, pointing in the direction of steepest ascent of $\cL$.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Perform a gradient-step on the surface of the manifold in the negative direction of the tangent 
vector $\vv$, to get the updated parameters.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We’ll now look at these steps in more detail in what follows.&lt;/p&gt;

&lt;h3 id=&quot;computation-of-gradient-wrt-current-parameters&quot;&gt;Computation of Gradient w.r.t. Current Parameters&lt;/h3&gt;

&lt;p&gt;In order to minimize our loss function $\cL$, we first have to determine
the gradient. The gradient w.r.t. our parameters $\vtheta$, evaluated
at our current parameters $\vtheta^{(t)}$, is computed as follows:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\vh:=
\nabla_{\vtheta}\cL(\vtheta^{(t)}) 
= 
\vg^{-1}_{\vtheta^{(t)}}
\fpartial{\cL(\vtheta^{(t)})}{\vtheta}.&lt;/script&gt;

&lt;p&gt;The computation and evaluation of the derivatives $\fpartial{\cL(\vtheta^{(t)})}{\vtheta}$ is 
usually just performed automatically through the auto-differentiation functionality of our 
machine learning framework of choice. However, the multiplication with the 
inverse metric $\vg^{-1}_{\vtheta^{(t)}}$ usually has to be done manually in order to 
obtain the correct quantity for the gradient $\nabla_{\vtheta}\cL(\vtheta^{(t)})$.&lt;/p&gt;

&lt;p&gt;If that should be new to you that we have to multiply the partial derivatives
by the inverse of the metric tensor $\vg^{-1}_{\vtheta^{(t)}}$ to obtain the
gradient then don’t worry too much about that now. Let me just tell you
that, actually, that’s how the gradient is defined in general. The reason you 
might have never come across this multiplication by the inverse metric tensor 
is that for the usual Euclidean vector space, with the usual Cartesian coordinate 
system, the inverse metric tensor $\vg^{-1}$ just simplifies to the identity matrix $\MI$, 
and is therefore usually omitted for convenience.&lt;/p&gt;

&lt;p&gt;The reason behind the multiplication by the inverse metric tensor is that
we want the gradient to be a vector that is &lt;em&gt;invariant&lt;/em&gt; under the choice
of a specific coordinate system. Furthermore, it should satisfy 
the following two properties that we already know from the gradient in Euclidean 
vector spaces:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The gradient evaluated at $\vtheta^{(t)}$ points into the direction of
steepest ascent of $\cL$ at $\vtheta^{(t)}$.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The norm of the gradient at $\vtheta^{(t)}$ is equal to the
value of the directional derivative in a unit vector of the gradient’s direction.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Explaining the reasons behind the multiplication with $\vg^{-1}_{\vtheta^{(t)}}$ in more detail
would explode the scope of this blogbost. However, in case you should want to learn more about 
this, I highly recommend that you have a look  at 
&lt;a href=&quot;https://www.youtube.com/watch?v=e0eJXttPRZI&amp;amp;list=PLlXfTHzgMRULkodlIEqfgTS-H1AY_bNtq&amp;amp;index=1&quot;&gt;
Pavel Grinfield’s valuable lectures on tensor calculus&lt;/a&gt; (until 
Lesson 5a for the gradient), where you can learn the reasons behind the 
multiplication with the inverse metric tensor in a matter of a few hours.&lt;/p&gt;

&lt;h3 id=&quot;orthogonal-projection-of-gradient-onto-tangent-space&quot;&gt;Orthogonal Projection of Gradient onto Tangent Space&lt;/h3&gt;

&lt;p&gt;Since the previously computed gradient $\vh=\nabla_{\vtheta}\cL(\vtheta^{(t)})$ may be lying 
just somewhere in ambient space, we first have to determine the component of $\vh$ that lies in 
the tangent space at $\vtheta^{(t)}$. The situation is illustrated in the figure below, where 
we can see our manifold $\cM$, the gradient $\vh$ lying in the ambient space, and the tangent 
space $\cT_{\vtheta^{(t)}}\cM$, which represents a first-order approximation of the manifold’s 
surface around our current parameters $\vtheta^{(t)}$.&lt;/p&gt;

&lt;div class=&quot;figure-with-caption&quot;&gt;
&lt;img src=&quot;/img/2019-10-15-Stochastic-Gradient-Descent-on-Riemannian-Manifolds/rsgd-steps/orthogonal-projection-of-gradient-onto-tangent-space.png?v=1&quot; alt=&quot;Orthogonal Projection of Gradient onto Tangent Space&quot; width=&quot;70%&quot; /&gt;
&lt;div class=&quot;figure-caption&quot; style=&quot;text-align:center&quot;&gt;
Orthogonal Projection of Gradient $\vh=\nabla_{\vtheta}\cL(\vtheta^{(t)})$ 
onto Tangent Space $\cT_{\vtheta^{(t)}}\cM$
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;The component of $\vh$ that lies in $\cT_{\vtheta^{(t)}}\cM$ is determined through
the orthogonal projection of $\vh$ from the ambient space onto the tangent space 
$\cT_{\vtheta^{(t)}}\cM$:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\vv=\proj_{\cT_{\vtheta^{(t)}}\cM}(\vh).&lt;/script&gt;

&lt;p&gt;Depending on the chosen representation for the manifold $\cM$ it might even be that 
the orthogonal projection is not even necessary, e.g., in the case where any tangent 
space is always equal to the ambient space.&lt;/p&gt;

&lt;h3 id=&quot;gradient-step-from-tangent-vector&quot;&gt;Gradient Step from Tangent Vector&lt;/h3&gt;

&lt;p&gt;Having determined the direction of steepest increase $\vv$ of $\cL$ in the tangent space
$\cT_{\vtheta^{(t)}}\cM$ we can now use it to perform a gradient step. As with 
the usual SGD, we want to take a step in the &lt;em&gt;negative&lt;/em&gt; gradient direction in order
to hopefully &lt;em&gt;decrease&lt;/em&gt; the loss. Thus, in the tangent space, we take a step in the 
direction of $-\eta_t\vv$, where $\eta_t$ is our learning rate, and obtain
the point $-\eta_t\vv$ in the tangent space $\cT_{\vtheta^{(t)}}$.&lt;/p&gt;

&lt;p&gt;Recall, that the tangent space $\cT_{\vtheta^{(t)}}$ represents a first-order 
approximation of the manifold’s smooth surface at the point $\vtheta^{(t)}$. Hence,
the vector $-\eta_t\vv\in\cT_{\vtheta^{(t)}}$ is in a direct correspondence with the 
point $\vtheta^{(t+1)}\in\cM$ that we’d like to reach through our gradient update. The mapping 
which maps tangent vectors to their corresponding points on the manifold is exactly the 
exponential map. Thus, we may just map $-\eta_t\vv$ to $\vtheta^{(t+1)}$ via the exponential map
to perform our gradient update:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\vtheta^{(t+1)}
=
\exp_{\vtheta^{(t)}}(-\eta_t\vv).&lt;/script&gt;

&lt;p&gt;The gradient-step is illustrated in the figure below. As one can observe, the exponential 
map is exactly what makes the parameters stay on the surface and also what forces 
gradient updates to follow the curved geodesics of the manifold.&lt;/p&gt;

&lt;div class=&quot;figure-with-caption&quot;&gt;
&lt;img src=&quot;/img/2019-10-15-Stochastic-Gradient-Descent-on-Riemannian-Manifolds/rsgd-steps/gradient-step-via-expmap.png?v=1&quot; alt=&quot;Orthogonal Projection of Gradient onto Tangent Space&quot; width=&quot;70%&quot; /&gt;
&lt;div class=&quot;figure-caption&quot; style=&quot;text-align:center&quot;&gt;
Gradient Step via Exponential Map
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Another equivalent way of seeing the gradient update is the following: The mapping 
which moves the point $\vtheta^{(t)}\in\cM$ in the initial direction $-\vv$
along a geodesic of length $\norm{\eta_t\vv}_{\vtheta^{(t)}}$ is exactly the 
exponential map $\exp_{\vtheta^{(t)}}(\argdot)$.&lt;/p&gt;

&lt;p&gt;Sometimes, as mentioned by Bonnabel in &lt;a class=&quot;citation&quot; href=&quot;#bonnabel&quot;&gt;[2]&lt;/a&gt;, for computational 
efficiency reasons or when it’s hard to solve the differential equations to obtain the 
exponential map, the gradient step is also approximated through the retraction $\cR_{\vx}(\vv)$:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\cR_{\vx}(\vv):=\proj_{\cM}(\vx+\vv),&lt;/script&gt;

&lt;p&gt;where the function $\proj_\cM$ is the orthogonal projection from the ambient space (that
includes the tangent space) onto the manifold $\cM$. Hence, the retraction represents a 
first-order approximation of the exponential map. The possible differences between parameter 
updates through the exponential map and the retraction are illustrated in the figure below:&lt;/p&gt;

&lt;div class=&quot;figure-with-caption&quot;&gt;
&lt;img src=&quot;/img/2019-10-15-Stochastic-Gradient-Descent-on-Riemannian-Manifolds/rsgd-steps/expmap-vs-retraction.png?v=2&quot; alt=&quot;Exponential Map VS Retraction&quot; width=&quot;70%&quot; /&gt;
&lt;div class=&quot;figure-caption&quot; style=&quot;text-align:center&quot;&gt;
Exponential Map VS Retraction
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;As one can see the retraction first follows a straight line in the tangent space and then 
orthogonally projects the point in the tangent space onto the manifold. The exponential map 
instead performs exact updates along to the manifold’s curved geodesics with a geodesic length
that corresponds to the tangent space norm of the tangent vector $-\eta_t\vv$. Therefore, the 
different update methods may lead to different parameter updates. Which one is better to use depends on the 
specific manifold, the computational cost of the exponential map, the size of the gradient-steps 
and the behaviour of the loss function.&lt;/p&gt;

&lt;p&gt;To summarize, all we need to perform RSGD is 1) the inverse of the metric tensor, 2) 
the formula for the orthogonal projection onto tangent spaces, and 3) the exponential map
or the retraction to map tangent vectors to corresponding points on the manifold.
The formulas for the steps 1)-3) vary from manifold to manifold and can usually
be found in papers or other online resources. Here are few resources, that give the concrete 
formulas for some useful manifolds:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Poincaré Ball:&lt;/strong&gt;
&lt;a href=&quot;https://papers.nips.cc/paper/7213-poincare-embeddings-for-learning-hierarchical-representations.pdf&quot;&gt;
Nickel, Maximillian, and Douwe Kiela. “Poincaré embeddings for learning hierarchical 
representations.” Advances in neural information processing systems. 2017.
&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Sphere &amp;amp; Hyperboloid:&lt;/strong&gt; 
&lt;a href=&quot;http://eprints.whiterose.ac.uk/78407/1/SphericalFinal.pdf&quot;&gt;
Wilson, Richard C., et al. “Spherical and hyperbolic embeddings of data.” IEEE transactions on 
pattern analysis and machine intelligence 36.11 (2014): 2255-2269.
&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Birkhoff Polytope:&lt;/strong&gt;
&lt;a href=&quot;http://openaccess.thecvf.com/content_CVPR_2019/papers/Birdal_Probabilistic_Permutation_Synchronization_Using_the_Riemannian_Structure_of_the_Birkhoff_CVPR_2019_paper.pdf&quot;&gt;
Birdal, Tolga, and Umut Simsekli. “Probabilistic Permutation Synchronization using the 
Riemannian Structure of the Birkhoff Polytope.” Proceedings of the IEEE Conference on Computer 
Vision and Pattern Recognition. 2019.
&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Grassmannian Manifold:&lt;/strong&gt;
&lt;a href=&quot;https://arxiv.org/pdf/1808.02229.pdf&quot;&gt;
Zhang, Jiayao, et al. “Grassmannian learning: Embedding geometry awareness in shallow and deep 
learning.” arXiv preprint arXiv:1808.02229 (2018).
&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Several other Matrix Manifolds:&lt;/strong&gt;
&lt;a href=&quot;https://www.researchgate.net/profile/Rodolphe_Sepulchre/publication/220693013_Optimization_Algorithms_on_Matrix_Manifolds/links/09e4150b8678c0da06000000/Optimization-Algorithms-on-Matrix-Manifolds.pdf&quot;&gt;
Absil, P-A., Robert Mahony, and Rodolphe Sepulchre. Optimization algorithms on matrix manifolds. 
Princeton University Press, 2009.
&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;riemannian-sgd-on-products-of-riemannian-manifolds&quot;&gt;Riemannian SGD on Products of Riemannian Manifolds&lt;/h2&gt;

&lt;p&gt;Since Cartesian products of Riemannian manifolds are again Riemannian manifolds, RSGD can also
be applied in these product spaces. In this case, let $(\cP,\vg)$ be a product of $n$ Riemannian 
manifolds $(\cM_i,\vg_i)_{i=1}^n$, and let $\vg$ be the induced product metric:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\cP:=\cM_1\times\cdots\times\cM_n,
\qquad
\vg:=\begin{pmatrix}
\vg_1 &amp; &amp; \\
&amp; \ddots &amp; \\
&amp; &amp; \vg_n
\end{pmatrix}. %]]&gt;&lt;/script&gt;

&lt;p&gt;Furthermore, let the optimization problem on $\cP$ be&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\vtheta^*=\argmin_{\vtheta\in\cP}\cL(\vtheta).&lt;/script&gt;

&lt;p&gt;Then, the nice thing with product spaces is that the exponential map in the product 
space $\cP$ simply decomposes into the concatenation of the exponential maps of the 
individual factors $\cM_i$. Similarly, the orthogonal projection and the gradient 
computations also decompose into the corresponding individual operations on the 
product’s factors. Hence, RSGD on products of Riemannian manifolds is simply achieved 
by performing the aforementioned gradient-step procedure separately for each of the manifold’s 
factors. A concrete algorithm for product spaces is given in the algorithm below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2019-10-15-Stochastic-Gradient-Descent-on-Riemannian-Manifolds/rsgd-algo.svg?v=5&quot; alt=&quot;RSGD Algorithm&quot; width=&quot;100%&quot; style=&quot;margin-top:40px;margin-bottom:40px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;riemannian-adaptive-optimization-methods&quot;&gt;Riemannian Adaptive Optimization Methods&lt;/h2&gt;

&lt;p&gt;The successful applications of Riemannian manifolds in machine learning impelled Gary 
Bécigneul and Octavian Ganea to further generalize adaptive optimization algorithms such 
as ADAM, ADAGRAD and AMSGRAD to products of Riemannian manifolds. For the details of the adaptive
optimization methods I refer you to their paper &lt;a class=&quot;citation&quot; href=&quot;#riemannianadaptive&quot;&gt;[3]&lt;/a&gt;. A ready-to-use pytorch implementation of their proposed optimization algorithms, along with 
the implementation of several manifolds, has been published on github by Maxim Kochurov in his 
geometric optimization library called geoopt:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/geoopt/geoopt/blob/master/geoopt/optim/rsgd.py&quot;&gt;Riemannian SGD&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://github.com/geoopt/geoopt/blob/master/geoopt/optim/radam.py&quot;&gt;Riemannian ADAM&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We’ll use the Riemannian ADAM (RADAM) in the code-example that follows in order to see
how to perform Riemannian optimization in product spaces with geoopt.&lt;/p&gt;

&lt;h2 id=&quot;code-example-for-riemannian-optimization-in-product-spaces&quot;&gt;Code Example for Riemannian Optimization in Product Spaces&lt;/h2&gt;

&lt;p&gt;Here’s a simple code example that shows how to perform Riemannian optimization in
a product space. In this example, we’ll optimize the embedding of a graph $G$
that is a &lt;em&gt;cycle&lt;/em&gt; of $n=20$ nodes such that their original graph-distances $d_G(x_i,x_j)$ are 
preserved as well as possible in the geodesic distances $d_{\cP}(x_i,x_j)$ of the arrangement of 
the embeddings in the product space $\cP$. The product space that we’ll choose in our example is
a torus (product of two circles). And the loss that we’ll optimize is just the squared loss of 
the graph and product space distances:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\cL(\vtheta)=\sum_{i,j} \left(d_G(x_i,x_j)-d_{\cP}(x_i,x_j)\right)^2.&lt;/script&gt;

&lt;p&gt;The following plot shows how the positions of the embeddings evolve over time and finally 
arrange in a setting that approximates the original graph distances of the cycle graph.&lt;/p&gt;

&lt;div class=&quot;figure-with-caption&quot;&gt;
&lt;img src=&quot;/img/2019-10-15-Stochastic-Gradient-Descent-on-Riemannian-Manifolds/graph-embedding.gif?v=2&quot; alt=&quot;Evolution of Graph Embedding in Product Space&quot; width=&quot;70%&quot; /&gt;
&lt;div class=&quot;figure-caption&quot; style=&quot;text-align:center&quot;&gt;
Evolution of Graph Embedding in Product Space
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Here’s the code that shows how the optimization of this graph embedding is performed:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;geoopt&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ManifoldTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ManifoldParameter&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;geoopt.manifolds&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SphereExact&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Scaled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ProductManifold&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;geoopt.optim&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RiemannianAdam&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sin&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;mayavi&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mlab&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;imageio&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tqdm&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tqdm&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# CREATE CYCLE GRAPH ###########################################################
&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Here we prepare a graph that is a cycle of n nodes. We then compute all pair-
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# wise graph distances because we'll want to learn an embedding that embeds the
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# vertices of the graph on the surface of a torus, such that the distances of
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# the induced discrete metric space of the graph are preserved as well as
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# possible through the positioning of the embeddings on the torus.
&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;training_examples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# only consider pair-wise distances below diagonal of distance matrix
&lt;/span&gt;    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# determine distance between vertice i and j
&lt;/span&gt;        
        &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# scale down distance
&lt;/span&gt;        
        &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# add edge and weight to training examples
&lt;/span&gt;        
        &lt;span class=&quot;n&quot;&gt;training_examples&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# the training_examples now consist of a list of triplets (v1, v2, d)
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# where v1, v2 are vertices, and d is their (scaled) graph distance
&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# CREATION OF PRODUCT SPACE (TORUS) ############################################
&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# create first sphere manifold of radius 1 (default)
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# (the Exact version uses the exponential map instead of the retraction)
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;r1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sphere1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SphereExact&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# create second sphere manifold of radius 0.3
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;r2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sphere2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Scaled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SphereExact&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# create torus manifold through product of two 1-dimensional spheres (actually
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# circles) which are each embedded in a 2D ambient space
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;torus&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ProductManifold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sphere1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sphere2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# INITIALIZATION OF EMBEDDINGS #################################################
&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# init embeddings. sidenote: this initialization was mostly chosen for
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# illustration purposes. you may want to consider better initialization
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# strategies for the product space that you'll consider.
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# augment embeddings tensor to a manifold tensor with a reference to the product
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# manifold that they belong to such that the optimizer can determine how to
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# convert the the derivatives of pytorch to the correct Riemannian gradients
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ManifoldTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;manifold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# project the embeddings onto the spheres' surfaces (in-place) according to the
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# orthogonal projection from ambient space onto the sphere's surface for each
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# spherical factor
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;proj_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# declare the embeddings as trainable manifold parameters
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ManifoldParameter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# PLOTTING FUNCTIONALITY #######################################################
&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# array storing screenshots
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;screenshots&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# torus surface
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mgrid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;100j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;100j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;torus_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;torus_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;torus_z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# embedding point surface
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ball_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.035&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ball_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ball_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ball_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ball_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ball_z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ball_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;plot_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;point_color&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;62&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;160&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mlab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mesh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ball_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ball_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ball_z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;point_color&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;update_plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# transform embedding (2D X 2D)-coordinates to 3D coordinates on torus
&lt;/span&gt;    
    &lt;span class=&quot;n&quot;&gt;cos_phi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sin_phi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;xx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cos_phi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r2&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;yy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sin_phi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r2&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;zz&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# create figure
&lt;/span&gt;    
    &lt;span class=&quot;n&quot;&gt;mlab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;700&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bgcolor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# plot torus surface
&lt;/span&gt;    
    &lt;span class=&quot;n&quot;&gt;torus_color&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mlab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mesh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torus_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torus_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torus_z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torus_color&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opacity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# plot embedding points on torus surface
&lt;/span&gt;    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plot_point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zz&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# save screenshot
&lt;/span&gt;    
    &lt;span class=&quot;n&quot;&gt;mlab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;azimuth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;elevation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;focalpoint&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mlab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gcf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scene&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_lift&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;screenshots&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mlab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;screenshot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;antialiased&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mlab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# TRAINING OF EMBEDDINGS IN PRODUCT SPACE ######################################
&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# build RADAM optimizer and specify the embeddings as parameters.
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# note that the RADAM can also optimize parameters which are not attached to a
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# manifold. then it just behaves like the usual ADAM for the Euclidean vector
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# space. we stabilize the embedding every 1 steps, which rthogonally projects
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# the embedding points onto the manifold's surface after the gradient-updates to
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# ensure that they lie precisely on the surface of the manifold. this is needed
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# because the parameters may get slightly off the manifold's surface for
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# numerical reasons. Not stabilizing may introduce small errors that accumulate
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# over time.
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;riemannian_adam&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RiemannianAdam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stabilize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# we'll just use this as a random examples sampler to get some stochasticity
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# in our gradient descent
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;num_training_examples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;training_examples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;training_example_indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_training_examples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_subset_of_examples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;choice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;training_example_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                 &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_training_examples&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                                 &lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# training loop to optimize the positions of embeddings such that the
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# distances between them become as close as possible to the true graph distances
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tqdm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# zero-out the gradients
&lt;/span&gt;    
    &lt;span class=&quot;n&quot;&gt;riemannian_adam&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# compute loss for next batch
&lt;/span&gt;    
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;indices_batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_subset_of_examples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indices_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v_j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_distance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training_examples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# compute the current distances between the embeddings in the product
&lt;/span&gt;        
        &lt;span class=&quot;c1&quot;&gt;# space (torus)
&lt;/span&gt;        
        &lt;span class=&quot;n&quot;&gt;current_distance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torus&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v_j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:])&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# add squared loss of current and target distance to the loss
&lt;/span&gt;        
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;current_distance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_distance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# compute derivative of loss w.r.t. parameters
&lt;/span&gt;    
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# let RADAM compute the gradients and do the gradient step
&lt;/span&gt;    
    &lt;span class=&quot;n&quot;&gt;riemannian_adam&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# plot current embeddings
&lt;/span&gt;    
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;update_plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;detach&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# CREATE ANIMATED GIF ##########################################################
&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;imageio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mimsave&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'training.gif'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;screenshots&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;duration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Of course, one might choose better geometries to embed a cycle graph. Also,
a better embedding could have been achieved if the embeddings had wrapped
around the curved tube of the torus. This example was mostly chosen to have an illustrative 
minimal working example in order to get you started Riemannian optimization in product spaces. A 
paper that extensively studies the suitability of products of spaces of constant curvature to learn 
distance-preserving embeddings of real-world graphs is the work of Gu et al. 
&lt;a class=&quot;citation&quot; href=&quot;#productspaces&quot;&gt;[4]&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;That’s all for now, I hope that my motivation and explanation of RSGD was helpful 
to you and that you are now ready to get started with Riemannian optimization.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;ol class=&quot;bibliography&quot;&gt;&lt;li&gt;&lt;span id=&quot;douik2018manifold&quot;&gt;A. Douik and B. Hassibi, “Manifold Optimization Over the Set of Doubly Stochastic Matrices: A Second-Order Geometry,” &lt;i&gt;arXiv preprint arXiv:1802.02628&lt;/i&gt;, 2018.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;bonnabel&quot;&gt;S. Bonnabel, “Stochastic gradient descent on Riemannian manifolds,” &lt;i&gt;IEEE Transactions on Automatic Control&lt;/i&gt;, vol. 58, no. 9, pp. 2217–2229, 2013.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;riemannianadaptive&quot;&gt;G. Bécigneul and O.-E. Ganea, “Riemannian adaptive optimization methods,” &lt;i&gt;arXiv preprint arXiv:1810.00760&lt;/i&gt;, 2018.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span id=&quot;productspaces&quot;&gt;A. Gu, F. Sala, B. Gunel, and C. Ré, “Learning Mixed-Curvature Representations in Product Spaces,” 2018.&lt;/span&gt;&lt;/li&gt;&lt;/ol&gt;</content><author><name>Andreas Bloch under the assistance of Octavian Ganea and Gary Bécigneul</name></author><category term="Stochastic Gradient Descent" /><category term="SGD" /><category term="Riemannian Stochastic Gradient Descent" /><category term="RSGD" /><category term="Riemannian Optimization" /><category term="Riemannian Manifolds" /><category term="Geometric Deep Learning" /><summary type="html">Stochastic Gradient Descent (SGD) is the default workhorse for most of today's machine learning algorithms. While the majority of SGD applications is concerned with Euclidean spaces, recent advances also harnessed the potential of Riemannian manifolds. This blogpost explains how the concept of SGD is generalized to Riemannian manifolds.</summary></entry></feed>